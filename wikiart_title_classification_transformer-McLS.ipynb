{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ef929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 30 15:47:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P40           On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   19C    P8     9W / 250W |      0MiB / 23040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P40           On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   22C    P8     8W / 250W |      0MiB / 23040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85afaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1b389c5ae0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "import os\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def seed_everything(seed=12):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "RANDOM_SEED = 12\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95d6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed_wikiart_title.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786e6536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Token count')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "token_lens = []\n",
    "\n",
    "for txt in df.Title:\n",
    "    tokens = tokenizer.encode(txt, max_length=30)\n",
    "    token_lens.append(len(tokens))\n",
    "\n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 30]);\n",
    "plt.xlabel('Token count')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8f3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 30\n",
    "class Wikiart_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, title, targets, tokenizer, max_len):\n",
    "        self.title = title\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.title[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          review,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=True,\n",
    "          pad_to_max_length=True,\n",
    "          return_attention_mask=True,\n",
    "          \n",
    "          return_tensors='pt',\n",
    "        )\n",
    "        ids = encoding['input_ids']\n",
    "        mask = encoding['attention_mask']\n",
    "       \n",
    "        \n",
    "        return {\n",
    "          \n",
    "          'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "           'mask': torch.tensor(mask, dtype=torch.long),\n",
    "           'targets': torch.tensor(self.targets[item], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a3a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e91254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'mask', 'targets'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = Wikiart_Dataset(\n",
    "    title=df.Title.to_numpy(),\n",
    "    targets=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "    return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2\n",
    "  )\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "data = next(iter(train_data_loader))\n",
    "data.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6689b2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "n_classes=6\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=n_classes).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c1e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 6\n",
    "conf_score= torch.tensor([0.8871, 0.8848, 0.8912, 0.8898, 0.7549, 0.8843]).to(device)\n",
    "class CE_LS_MC(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, classes= num_classes, smoothing=0.13, ignore_index=-1):\n",
    "        super(CE_LS_MC, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.complement = 1.0 - smoothing\n",
    "        self.cls = classes\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, logits, target, conf_score):\n",
    "        with torch.no_grad():\n",
    "            new_smoothing  = self.smoothing + conf_score/100\n",
    "            new_complement = 1 - new_smoothing\n",
    "            oh_labels = F.one_hot(target.to(torch.int64), num_classes = self.cls).contiguous()\n",
    "            smoothen_ohlabel = oh_labels * new_complement + new_smoothing / self.cls\n",
    "        \n",
    "        logs = self.log_softmax(logits[target!=self.ignore_index])\n",
    "        return -torch.sum(logs * smoothen_ohlabel[target!=self.ignore_index], dim=1).mean()\n",
    "\n",
    "loss_fn = CE_LS_MC(classes = num_classes).to(device)\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask = d[\"mask\"].squeeze(1).to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        ).logits\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets.long(),conf_score)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask = d[\"mask\"].squeeze(1).to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                ).logits\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets.long(),conf_score)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60efb462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Train loss 1.2537124428934263 accuracy 0.6141900121802679\n",
      "Val loss 1.1838452128263621 accuracy 0.6577344701583434\n",
      "\n",
      "epoch: 0  acc: 0.6577  best epoch: 0  best acc: 0.6577 lr: 0.0000\n",
      "Epoch 2/100\n",
      "----------\n",
      "Train loss 0.99526576856965 accuracy 0.771619975639464\n",
      "Val loss 1.1966524376319005 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 1  acc: 0.6675  best epoch: 1  best acc: 0.6675 lr: 0.0000\n",
      "Epoch 3/100\n",
      "----------\n",
      "Train loss 0.8456651828821423 accuracy 0.8514007308160779\n",
      "Val loss 1.2590360847803264 accuracy 0.684531059683313\n",
      "\n",
      "epoch: 2  acc: 0.6845  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 4/100\n",
      "----------\n",
      "Train loss 0.7556783441200997 accuracy 0.8952496954933008\n",
      "Val loss 1.3196379427726452 accuracy 0.6528623629719853\n",
      "\n",
      "epoch: 3  acc: 0.6529  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 5/100\n",
      "----------\n",
      "Train loss 0.6973324510657671 accuracy 0.9241778319123021\n",
      "Val loss 1.342955162891975 accuracy 0.6601705237515225\n",
      "\n",
      "epoch: 4  acc: 0.6602  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 6/100\n",
      "----------\n",
      "Train loss 0.6537691285309283 accuracy 0.9464068209500609\n",
      "Val loss 1.3554008373847375 accuracy 0.6784409257003654\n",
      "\n",
      "epoch: 5  acc: 0.6784  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 7/100\n",
      "----------\n",
      "Train loss 0.6307100115470516 accuracy 0.9610231425091351\n",
      "Val loss 1.376447313106977 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 6  acc: 0.6638  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 8/100\n",
      "----------\n",
      "Train loss 0.6151863695348351 accuracy 0.9658952496954932\n",
      "Val loss 1.416247464143313 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 7  acc: 0.6638  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 9/100\n",
      "----------\n",
      "Train loss 0.6066385287682987 accuracy 0.9716808769792935\n",
      "Val loss 1.4179880985846887 accuracy 0.6613885505481121\n",
      "\n",
      "epoch: 8  acc: 0.6614  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 10/100\n",
      "----------\n",
      "Train loss 0.5996282737231949 accuracy 0.9716808769792935\n",
      "Val loss 1.4274562230476966 accuracy 0.6650426309378806\n",
      "\n",
      "epoch: 9  acc: 0.6650  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 11/100\n",
      "----------\n",
      "Train loss 0.5953441696259582 accuracy 0.9747259439707673\n",
      "Val loss 1.4421050456854014 accuracy 0.658952496954933\n",
      "\n",
      "epoch: 10  acc: 0.6590  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 12/100\n",
      "----------\n",
      "Train loss 0.593215592856546 accuracy 0.9759439707673568\n",
      "Val loss 1.4384293785462012 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 11  acc: 0.6626  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 13/100\n",
      "----------\n",
      "Train loss 0.5905097919760398 accuracy 0.9759439707673568\n",
      "Val loss 1.4417889484992394 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 12  acc: 0.6638  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 14/100\n",
      "----------\n",
      "Train loss 0.5872579205383375 accuracy 0.9780755176613884\n",
      "Val loss 1.4495506515869727 accuracy 0.6650426309378806\n",
      "\n",
      "epoch: 13  acc: 0.6650  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 15/100\n",
      "----------\n",
      "Train loss 0.5866411241512854 accuracy 0.976857490864799\n",
      "Val loss 1.447535244318155 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 14  acc: 0.6638  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 16/100\n",
      "----------\n",
      "Train loss 0.5847916273237432 accuracy 0.9780755176613884\n",
      "Val loss 1.4491673570412855 accuracy 0.6650426309378806\n",
      "\n",
      "epoch: 15  acc: 0.6650  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 17/100\n",
      "----------\n",
      "Train loss 0.5849155563752628 accuracy 0.9762484774665042\n",
      "Val loss 1.4538791867402883 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 16  acc: 0.6626  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 18/100\n",
      "----------\n",
      "Train loss 0.5842932184923042 accuracy 0.9771619975639464\n",
      "Val loss 1.4606174001326928 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 17  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 19/100\n",
      "----------\n",
      "Train loss 0.5829420512162365 accuracy 0.9777710109622411\n",
      "Val loss 1.459965366583604 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 18  acc: 0.6638  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 20/100\n",
      "----------\n",
      "Train loss 0.5811681209258663 accuracy 0.9771619975639464\n",
      "Val loss 1.4611013394135695 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 19  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 21/100\n",
      "----------\n",
      "Train loss 0.5825994743884189 accuracy 0.9777710109622411\n",
      "Val loss 1.4415244872753437 accuracy 0.6784409257003654\n",
      "\n",
      "epoch: 20  acc: 0.6784  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 22/100\n",
      "----------\n",
      "Train loss 0.5818588970934303 accuracy 0.9780755176613884\n",
      "Val loss 1.4446844229331384 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 21  acc: 0.6699  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 23/100\n",
      "----------\n",
      "Train loss 0.5818940736715076 accuracy 0.9756394640682094\n",
      "Val loss 1.4435504995859587 accuracy 0.6772228989037758\n",
      "\n",
      "epoch: 22  acc: 0.6772  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 24/100\n",
      "----------\n",
      "Train loss 0.5804583389782211 accuracy 0.979293544457978\n",
      "Val loss 1.4485819981648371 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 23  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 25/100\n",
      "----------\n",
      "Train loss 0.5807682443590998 accuracy 0.9771619975639464\n",
      "Val loss 1.4472252222207875 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 24  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 26/100\n",
      "----------\n",
      "Train loss 0.5806676097286557 accuracy 0.9771619975639464\n",
      "Val loss 1.4519824706591093 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 25  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 27/100\n",
      "----------\n",
      "Train loss 0.5800231533143126 accuracy 0.9765529841656516\n",
      "Val loss 1.4597973708923047 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 26  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 28/100\n",
      "----------\n",
      "Train loss 0.5802251551915141 accuracy 0.9762484774665042\n",
      "Val loss 1.4605609316092272 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 27  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 29/100\n",
      "----------\n",
      "Train loss 0.5792109624853412 accuracy 0.9786845310596832\n",
      "Val loss 1.4647643978779132 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 28  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 30/100\n",
      "----------\n",
      "Train loss 0.5790250393950823 accuracy 0.9777710109622411\n",
      "Val loss 1.466632258433562 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 29  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 31/100\n",
      "----------\n",
      "Train loss 0.5798592480640967 accuracy 0.9765529841656516\n",
      "Val loss 1.459557620378641 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 30  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 32/100\n",
      "----------\n",
      "Train loss 0.5785929664824773 accuracy 0.9780755176613884\n",
      "Val loss 1.4697455213620112 accuracy 0.6650426309378806\n",
      "\n",
      "epoch: 31  acc: 0.6650  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 33/100\n",
      "----------\n",
      "Train loss 0.579135626843832 accuracy 0.9789890377588306\n",
      "Val loss 1.4547949960598578 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 32  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 34/100\n",
      "----------\n",
      "Train loss 0.578906707393313 accuracy 0.9771619975639464\n",
      "Val loss 1.4663384075348194 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 33  acc: 0.6675  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 35/100\n",
      "----------\n",
      "Train loss 0.5791480205591443 accuracy 0.9777710109622411\n",
      "Val loss 1.4796726245146532 accuracy 0.6613885505481121\n",
      "\n",
      "epoch: 34  acc: 0.6614  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 36/100\n",
      "----------\n",
      "Train loss 0.5789026982575944 accuracy 0.979293544457978\n",
      "Val loss 1.451685029726762 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 35  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 37/100\n",
      "----------\n",
      "Train loss 0.5786682841847244 accuracy 0.9786845310596832\n",
      "Val loss 1.4621609082588782 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 36  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 38/100\n",
      "----------\n",
      "Train loss 0.5783137563362862 accuracy 0.9795980511571254\n",
      "Val loss 1.4585432410240173 accuracy 0.6747868453105969\n",
      "\n",
      "epoch: 37  acc: 0.6748  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 39/100\n",
      "----------\n",
      "Train loss 0.5790872747458301 accuracy 0.9795980511571254\n",
      "Val loss 1.4637369375962477 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 38  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 40/100\n",
      "----------\n",
      "Train loss 0.5784168741078053 accuracy 0.9802070645554202\n",
      "Val loss 1.457752512051509 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 39  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 41/100\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5780704478615696 accuracy 0.979293544457978\n",
      "Val loss 1.461098313331604 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 40  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 42/100\n",
      "----------\n",
      "Train loss 0.5786262698543881 accuracy 0.9783800243605358\n",
      "Val loss 1.4533552756676307 accuracy 0.6796589524969548\n",
      "\n",
      "epoch: 41  acc: 0.6797  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 43/100\n",
      "----------\n",
      "Train loss 0.5791702426752998 accuracy 0.9789890377588306\n",
      "Val loss 1.4706178124134357 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 42  acc: 0.6699  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 44/100\n",
      "----------\n",
      "Train loss 0.5778315900598915 accuracy 0.9799025578562728\n",
      "Val loss 1.4752800877277668 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 43  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 45/100\n",
      "----------\n",
      "Train loss 0.5781429919224341 accuracy 0.9795980511571254\n",
      "Val loss 1.4576175075310926 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 44  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 46/100\n",
      "----------\n",
      "Train loss 0.5782759774078443 accuracy 0.979293544457978\n",
      "Val loss 1.4612044325241675 accuracy 0.6650426309378806\n",
      "\n",
      "epoch: 45  acc: 0.6650  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 47/100\n",
      "----------\n",
      "Train loss 0.5776899167634908 accuracy 0.9795980511571254\n",
      "Val loss 1.4507771822122426 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 46  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 48/100\n",
      "----------\n",
      "Train loss 0.5770775247546076 accuracy 0.9795980511571254\n",
      "Val loss 1.471896923505343 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 47  acc: 0.6675  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 49/100\n",
      "----------\n",
      "Train loss 0.5775949497824734 accuracy 0.9802070645554202\n",
      "Val loss 1.4587544271579156 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 48  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 50/100\n",
      "----------\n",
      "Train loss 0.5776087392881079 accuracy 0.9783800243605358\n",
      "Val loss 1.4649496582838206 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 49  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 51/100\n",
      "----------\n",
      "Train loss 0.5778953826543197 accuracy 0.9789890377588306\n",
      "Val loss 1.4942332185231721 accuracy 0.6577344701583434\n",
      "\n",
      "epoch: 50  acc: 0.6577  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 52/100\n",
      "----------\n",
      "Train loss 0.5774303408502375 accuracy 0.9811205846528623\n",
      "Val loss 1.4718223305848928 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 51  acc: 0.6675  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 53/100\n",
      "----------\n",
      "Train loss 0.5768335693090865 accuracy 0.9799025578562728\n",
      "Val loss 1.4748049011597266 accuracy 0.6613885505481121\n",
      "\n",
      "epoch: 52  acc: 0.6614  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 54/100\n",
      "----------\n",
      "Train loss 0.5779068446853786 accuracy 0.9789890377588306\n",
      "Val loss 1.4680196688725398 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 53  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 55/100\n",
      "----------\n",
      "Train loss 0.5774305671164133 accuracy 0.9786845310596832\n",
      "Val loss 1.4633792913877046 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 54  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 56/100\n",
      "----------\n",
      "Train loss 0.5772997898962892 accuracy 0.979293544457978\n",
      "Val loss 1.4693437264515803 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 55  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 57/100\n",
      "----------\n",
      "Train loss 0.5770463173829236 accuracy 0.979293544457978\n",
      "Val loss 1.4698408429439251 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 56  acc: 0.6675  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 58/100\n",
      "----------\n",
      "Train loss 0.5770001758649511 accuracy 0.9799025578562728\n",
      "Val loss 1.464678901892442 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 57  acc: 0.6699  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 59/100\n",
      "----------\n",
      "Train loss 0.5767190109178858 accuracy 0.9799025578562728\n",
      "Val loss 1.472957349740542 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 58  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 60/100\n",
      "----------\n",
      "Train loss 0.5774095446160696 accuracy 0.9783800243605358\n",
      "Val loss 1.4738020988611074 accuracy 0.6613885505481121\n",
      "\n",
      "epoch: 59  acc: 0.6614  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 61/100\n",
      "----------\n",
      "Train loss 0.5776862930325628 accuracy 0.9789890377588306\n",
      "Val loss 1.4732168362690852 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 60  acc: 0.6626  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 62/100\n",
      "----------\n",
      "Train loss 0.577251388609988 accuracy 0.9789890377588306\n",
      "Val loss 1.4770644582234895 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 61  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 63/100\n",
      "----------\n",
      "Train loss 0.5771581692603028 accuracy 0.979293544457978\n",
      "Val loss 1.4785774396016047 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 62  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 64/100\n",
      "----------\n",
      "Train loss 0.5768084653372904 accuracy 0.9802070645554202\n",
      "Val loss 1.4720217127066393 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 63  acc: 0.6699  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 65/100\n",
      "----------\n",
      "Train loss 0.5769934850989036 accuracy 0.9799025578562728\n",
      "Val loss 1.4691129189271193 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 64  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 66/100\n",
      "----------\n",
      "Train loss 0.5771970621590475 accuracy 0.9802070645554202\n",
      "Val loss 1.4724302154320936 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 65  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 67/100\n",
      "----------\n",
      "Train loss 0.5764184443696031 accuracy 0.9789890377588306\n",
      "Val loss 1.4713379190518305 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 66  acc: 0.6675  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 68/100\n",
      "----------\n",
      "Train loss 0.5764324543545547 accuracy 0.9799025578562728\n",
      "Val loss 1.4693791958001943 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 67  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 69/100\n",
      "----------\n",
      "Train loss 0.5769139024817828 accuracy 0.979293544457978\n",
      "Val loss 1.4693607687950134 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 68  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 70/100\n",
      "----------\n",
      "Train loss 0.5767295800366448 accuracy 0.9814250913520097\n",
      "Val loss 1.4968861937522888 accuracy 0.658952496954933\n",
      "\n",
      "epoch: 69  acc: 0.6590  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 71/100\n",
      "----------\n",
      "Train loss 0.5770862490228079 accuracy 0.979293544457978\n",
      "Val loss 1.4662612951718843 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 70  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 72/100\n",
      "----------\n",
      "Train loss 0.5765127088259725 accuracy 0.9789890377588306\n",
      "Val loss 1.4663380751243005 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 71  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 73/100\n",
      "----------\n",
      "Train loss 0.5765546172567941 accuracy 0.9799025578562728\n",
      "Val loss 1.471617157642658 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 72  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 74/100\n",
      "----------\n",
      "Train loss 0.5766952402383378 accuracy 0.9802070645554202\n",
      "Val loss 1.461841037640205 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 73  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 75/100\n",
      "----------\n",
      "Train loss 0.5765417692730728 accuracy 0.9789890377588306\n",
      "Val loss 1.4577641028624315 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 74  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 76/100\n",
      "----------\n",
      "Train loss 0.5765577149622648 accuracy 0.9802070645554202\n",
      "Val loss 1.4636498781350942 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 75  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 77/100\n",
      "----------\n",
      "Train loss 0.5768493541236063 accuracy 0.9802070645554202\n",
      "Val loss 1.463012145115779 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 76  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 78/100\n",
      "----------\n",
      "Train loss 0.5763706848459337 accuracy 0.9817295980511571\n",
      "Val loss 1.4623995148218596 accuracy 0.6747868453105969\n",
      "\n",
      "epoch: 77  acc: 0.6748  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 79/100\n",
      "----------\n",
      "Train loss 0.5765014394973088 accuracy 0.9820341047503045\n",
      "Val loss 1.4651511494929974 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 78  acc: 0.6699  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 80/100\n",
      "----------\n",
      "Train loss 0.5769098117513564 accuracy 0.980816077953715\n",
      "Val loss 1.4599493512740502 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 79  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 81/100\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5765240533837994 accuracy 0.979293544457978\n",
      "Val loss 1.4666882065626292 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 80  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 82/100\n",
      "----------\n",
      "Train loss 0.5762138731271318 accuracy 0.980816077953715\n",
      "Val loss 1.4627714111254766 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 81  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 83/100\n",
      "----------\n",
      "Train loss 0.5768961588155876 accuracy 0.9817295980511571\n",
      "Val loss 1.4547021343157842 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 82  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 84/100\n",
      "----------\n",
      "Train loss 0.5763143202633534 accuracy 0.9802070645554202\n",
      "Val loss 1.4552183334644024 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 83  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 85/100\n",
      "----------\n",
      "Train loss 0.5764539664231457 accuracy 0.980816077953715\n",
      "Val loss 1.455281688616826 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 84  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 86/100\n",
      "----------\n",
      "Train loss 0.5760921673867309 accuracy 0.9820341047503045\n",
      "Val loss 1.4582389088777394 accuracy 0.6808769792935444\n",
      "\n",
      "epoch: 85  acc: 0.6809  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 87/100\n",
      "----------\n",
      "Train loss 0.57607087116797 accuracy 0.9802070645554202\n",
      "Val loss 1.457055545770205 accuracy 0.682095006090134\n",
      "\n",
      "epoch: 86  acc: 0.6821  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 88/100\n",
      "----------\n",
      "Train loss 0.5765829711284453 accuracy 0.9799025578562728\n",
      "Val loss 1.4575857336704547 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 87  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 89/100\n",
      "----------\n",
      "Train loss 0.5764660262367101 accuracy 0.9802070645554202\n",
      "Val loss 1.464499450646914 accuracy 0.6772228989037758\n",
      "\n",
      "epoch: 88  acc: 0.6772  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 90/100\n",
      "----------\n",
      "Train loss 0.5757252764933317 accuracy 0.980816077953715\n",
      "Val loss 1.470934129678286 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 89  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 91/100\n",
      "----------\n",
      "Train loss 0.5759159401782508 accuracy 0.9802070645554202\n",
      "Val loss 1.4677034387221704 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 90  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 92/100\n",
      "----------\n",
      "Train loss 0.5759250533233569 accuracy 0.9811205846528623\n",
      "Val loss 1.4685744184714098 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 91  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 93/100\n",
      "----------\n",
      "Train loss 0.5765068397938626 accuracy 0.9811205846528623\n",
      "Val loss 1.4665482411017785 accuracy 0.6747868453105969\n",
      "\n",
      "epoch: 92  acc: 0.6748  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 94/100\n",
      "----------\n",
      "Train loss 0.576275389750027 accuracy 0.9817295980511571\n",
      "Val loss 1.4681997115795429 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 93  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 95/100\n",
      "----------\n",
      "Train loss 0.5758892697038003 accuracy 0.9814250913520097\n",
      "Val loss 1.4689314044438875 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 94  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 96/100\n",
      "----------\n",
      "Train loss 0.576323034115208 accuracy 0.9814250913520097\n",
      "Val loss 1.4705446775142963 accuracy 0.6747868453105969\n",
      "\n",
      "epoch: 95  acc: 0.6748  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 97/100\n",
      "----------\n",
      "Train loss 0.5760221637568428 accuracy 0.9805115712545676\n",
      "Val loss 1.4711575645666857 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 96  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 98/100\n",
      "----------\n",
      "Train loss 0.5761012139829617 accuracy 0.9799025578562728\n",
      "Val loss 1.4708707057512724 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 97  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 99/100\n",
      "----------\n",
      "Train loss 0.5758775443706697 accuracy 0.980816077953715\n",
      "Val loss 1.4708276711977446 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 98  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 100/100\n",
      "----------\n",
      "Train loss 0.5764783973832732 accuracy 0.979293544457978\n",
      "Val loss 1.4712462700330293 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 99  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_everything()\n",
    "EPOCHS = 100\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "            \n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(model,train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train))\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(model,test_data_loader,loss_fn, device, len(df_test))\n",
    "\n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_wikiart_title_cls_transf_McLS.pth')\n",
    "        best_accuracy = val_acc\n",
    "        best_epoch = epoch\n",
    "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f} lr: {:.4f}'.format(\n",
    "            epoch, val_acc, best_epoch, best_accuracy,optimizer.param_groups[0]['lr']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971c4d4",
   "metadata": {},
   "source": [
    "Confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29edfea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8871, 0.8848, 0.8912, 0.8898, 0.7549, 0.8843], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_conf_freq (model, dataloader):\n",
    "    model.eval()\n",
    "    conf_score = torch.zeros([6]).to(device)\n",
    "    count = torch.zeros([6]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for d in dataloader:\n",
    "            input_ids = d[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask = d[\"mask\"].squeeze(1).to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                ).logits\n",
    "            softmaxes = F.softmax(outputs, dim=1)\n",
    "\n",
    "            for i in range (len(targets)):\n",
    "                 \n",
    "                confidence = softmaxes[i][targets[i].long()]\n",
    "                conf_score[targets[i].long()] += confidence\n",
    "                count[targets[i].long()] += 1\n",
    "            conf_avg = conf_score/count\n",
    "    return conf_avg\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_wikiart_title_cls_transf_LS_0.13.pth'))\n",
    "conf_score_train = get_conf_freq(model, train_data_loader)\n",
    "conf_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd811d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12b1c31",
   "metadata": {},
   "source": [
    "ECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62001e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08386115729808807"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "TRAIN_BATCH_SIZE=32\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_wikiart_title_cls_transf_McLS.pth'))\n",
    "\n",
    "labels = []\n",
    "for i in range(len(test_data_loader.dataset)):\n",
    "    label = test_data_loader.dataset[i]['targets']\n",
    "    labels.append(label)\n",
    "labels = np.array(labels)\n",
    "\n",
    "class _ECELoss(nn.Module):\n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(_ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece\n",
    "    \n",
    "def evaluation(model, testing_loader):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    pred_all = []\n",
    "    target_all = []\n",
    "    logits_list, labels_list = [], [] \n",
    "    with torch.no_grad():\n",
    "        for d in testing_loader:\n",
    "            input_ids = d[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask = d[\"mask\"].squeeze(1).to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            outputs = model(input_ids=input_ids,attention_mask=attention_mask).logits\n",
    "            loss_val = loss_fn(outputs, targets.long(),conf_score)\n",
    "            \n",
    "            predictions = torch.max(outputs, 1)[1].view(targets.size()).data\n",
    "            pred_all.append(outputs)\n",
    "            target_all.append(targets)\n",
    "            \n",
    "            f1 = f1_score(targets.data.cpu(), predictions.cpu(), average='macro')\n",
    "            num_corrects = (predictions == targets.data).float().sum()\n",
    "            acc = 100.0 * num_corrects / TRAIN_BATCH_SIZE\n",
    "            total_acc += acc.item()\n",
    "            total_loss += loss_val.item()\n",
    "            count += 1\n",
    "        logits_all = torch.cat(pred_all).cuda()\n",
    "        labels_all = torch.cat(target_all).cuda()\n",
    "    return total_acc/count,f1, logits_all, labels_all\n",
    "ece_criterion = _ECELoss().to(device)\n",
    "accuracy,total_f1, logits_all,labels_all = evaluation(model, test_data_loader)\n",
    "\n",
    "logits_all = logits_all.view(-1,6)\n",
    "labels_all = labels_all.view(-1)\n",
    "temperature_ece = ece_criterion(logits_all, labels_all).item()\n",
    "temperature_ece"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8b5931d",
   "metadata": {},
   "source": [
    "Reliability Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14075110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABAW0lEQVR4nO3dd3hUZfbA8e9JKAFC7y2E3kKHACodBAQpggXLig0ba9ldBDvW9adrX1cEOxYQEIxdUXoHhQARpAUCKCXUEBJSzu+PO4khpEySKSnn8zx5MjO3vOcOYc7c9733vKKqGGOMKbkC/B2AMcYY/7JEYIwxJZwlAmOMKeEsERhjTAlnicAYY0o4SwTGGFPCWSIwhZaILBaRW12PrxORH9zcbqqIfJTD8q0i0jfzuiISIiJxIhJY8OhzjO99EXna9biXiGz3ZnvG5MYSgSkSVPVjVb3UQ/tqq6qLs3h9n6oGq2oKnJ+IvEVVl6lqS2+2YUxuLBEYvxGRUv6OobgSh/3/Nm6xPxTjUyISLSKTRSQSOCMil4jIShE5ISKb0rpssthuvIgsz/D8VRGJEZFTIrJBRHpl2iRIRGaLyGkR+UVEOmSKYWAWbYSKiIpIKRF5BugF/NfVXfRfEXlDRF7MtE2EiNyfyzF3csVwWkRmA0EZlvUVkf0Znk8RkV2udaNEZHSGZYEi8qKIHBWRPSIyMS1e1/LFIvKMiKwA4oEmInKTiPzm2t9uEbk9c9si8oCIHBaRP0RklIhcJiK/i8gxEXkop2MzxYMlAuMP44BhQBPgC+BpoBrwL2CeiNR0Yx/rgI6u7T4B5ohIUIblI4E5GZYvEJHS7gaoqg8Dy4CJru6iicAHwLi0b9oiUgMY6Np/lkSkDLAAmOmKZQ4wJoemd+EkoMrAE8BHIlLXtew2YKjruDsDo7LY/gZgAlAR2AscBoYDlYCbgJdFpHOG9evgJKb6wGPADOB6oIsrjkdFpHEO8ZpiwBKB8YfXVDUG5wPnG1X9RlVTVfVHYD1wWW47UNWPVDVWVZNV9UWgLJCxr32Dqs5V1STgJZwPux4FCVpV1wIngQGul64BFqvqoRw26wGUBl5R1SRVnYuTxLJrY46qHnS9H7OBHUC4a/FVwKuqul9VjwPPZbGL91V1q+t9SVLVr1V1lzqWAD/gfMCnSQKecb1Ps4AarjZOq+pWIArocEErplixRGD8Icb1uxFwpatb6ISInAAuAepmu6WLiPzL1eVx0rVdZZwPscxtoKqpwH6gngdi/wAngeH6PTOX9esBB/T86o57s1tZRP4mIhszvB9h/HVc9chwXJkeZ/maiAwVkdWubp4TOEk24/sUmzY4Dpx1/c6Y2M4CwdnFa4oHG6wz/pD2oRgDzFTV2/KysWs84AGcb+ZbVTVVRI4DkmG1hhnWDwAaAAfzGWdGHwFbXGMOrXG6fXLyB1BfRCRDMgjB6QI6j4g0wumaGQCsUtUUEdnIX8f1h+s40jTkQukxi0hZYB7wN+ALVU0SkQWc/z4ZY2cExq8+Ai4XkcGugdAg1wBmg1y2qwgkA0eAUiLyGE4feEZdROQK10DqfUAisDqP8R3CGcdIp6r7cbp2ZgLzVPVsVhtmsMoV6z0iUlpEruCvrp7MKuB8kB8BEJGbcM4I0nwG3Csi9UWkCjA5l7bL4HSZHQGSRWQo4JFLcE3xYonA+I1rnGAk8BDOh1UMMInc/y6/B74DfsfpZkngwm6SL4CrgeM4A6hXuPrB8+JVYKyIHBeR1zK8/gHQjty7hVDVc8AVwHjgmCumz7NZNwp4ESd5HHK1sSLDKjNw+vgjgV+Bb3CSTApZUNXTwD04CeQ4cC0QkVvMpuQRm5jGmLwRkd44ZzON1I//gVzf8KepaiN/xWCKBzsjMCYPXJeg3gu87eskICLlXNf4lxKR+sDjwHxfxmCKJzsjMMZNItIa5/LWTcAQVT3lej0E5zLLrLRR1X0ear88sARohXM1z9fAvWlxGJNflgiMMaaEs64hY4wp4YrcfQQ1atTQ0NBQf4dhjDFFyoYNG46qapblW4pcIggNDWX9+vX+DsMYY4oUEcn2jnbrGjLGmBLOEoExxpRwlgiMMaaEK3JjBFlJSkpi//79JCQk+DsU40dBQUE0aNCA0qXdnnbAGEMxSQT79++nYsWKhIaGImKFFUsiVSU2Npb9+/fTuLHNo2JMXnita0hE3nVNf7clm+UiIq+JyE4Ricw0a1KeJCQkUL16dUsCJZiIUL16dTsrNCYfvDlG8D4wJIflQ4Hmrp8JwJsFacySgLG/AWPyx2uJQFWX4pTdzc5I4EPXFHqrgSoZ5mY1xhjjEn8umZhj8V7bvz+vGqrP+TXk97teu4CITBCR9SKy/siRIz4JLq8CAwPp2LEjYWFhXHnllcTH5+0fbdKkSbRt25ZJkyblue1nn30222VxcXHcfvvtNG3alC5dutC3b1/WrFmT4/5CQ0M5evQoABdddBEAixcvZvjw4XmOLaP333+fgwf/miTs1ltvJSoqu1ptxhiAlTuPMuSVZdzx0QZSU71TG65IXD6qqtNVtauqdq1ZM8s7pP2uXLlybNy4kS1btlCmTBmmTZvm1nbJyckATJ8+ncjISF544YU8t51TIrj11lupVq0aO3bsYMOGDbz33nvpH/LuWLlyZZ5iSUnJco4U4MJE8Pbbb9OmTZs87d+YkuLk2SSmzIvk2rfXECDw6PA2BAR4p/vTn4ngAOfPudrA9VqR16tXL3bu3MmZM2e4+eabCQ8Pp1OnTnzxxReA84E4YsQI+vfvz4ABAxgxYgRxcXF06dKF2bNnc+TIEcaMGUO3bt3o1q0bK1Y4k1TFxcVx00030a5dO9q3b8+8efOYMmUKZ8+epWPHjlx33XXnxbFr1y7WrFnD008/TUCA80/duHFjhg0bBsCoUaPo0qULbdu2Zfr06VkeS3DwX/OWnzp1imHDhtGyZUvuuOMOUlNT09f55z//SYcOHVi1ahVPPvkk3bp1IywsjAkTJqCqzJ07l/Xr13PdddfRsWNHzp49S9++fdPLhXz66ae0a9eOsLAwJk+efF77Dz/8MB06dKBHjx4cOnQIY4q7lFRlzJsr+Wx9DLf3acJ39/WmR5Pq3mtQVb32A4QCW7JZNgz4Fmci7R7AWnf22aVLF80sKirqvOdXTVt5wc+HK/eoqmp8YnKWyz9bt09VVWPjEi9Y5o4KFSqoqmpSUpKOGDFC//e//+mDDz6oM2fOVFXV48ePa/PmzTUuLk7fe+89rV+/vsbGxl6wvarquHHjdNmyZaqqunfvXm3VqpWqqj7wwAN67733pq937NixC7bN6IsvvtBRo0ZlG3Na+/Hx8dq2bVs9evSoqqo2atRIjxw5ct6+Fy1apGXLltVdu3ZpcnKyDhw4UOfMmaOqqoDOnj37gv2qql5//fUaERGhqqp9+vTRdevWpS9Le37gwAFt2LChHj58WJOSkrRfv346f/789H2nbT9p0iR96qmnsj0e1Qv/FowpSo7FJWpqaqqqqn67+Q/dFHPcY/sG1ms2n6teu49ARD4F+gI1RGQ/zmxKpV3JZxrOfKuXATuBeOAmb8XiC2nfysE5I7jlllu46KKLiIiI4D//+Q/gXOa6b58zR8mgQYOoVq1alvtauHDheX3np06dIi4ujoULFzJr1qz016tWrVqgmF977TXmz3cmuIqJiWHHjh1Ur579t47w8HCaNHHmch83bhzLly9n7NixBAYGMmbMmPT1Fi1axPPPP098fDzHjh2jbdu2XH755dnud926dfTt25e0br/rrruOpUuXMmrUKMqUKZM+NtGlSxd+/PHHAh2zMYWRqrJg4wGe+DKKyUNaMS48hCFhdXzWvtcSgaqOy2W5And7o+3Zt/fMdlm5MoE5Lq9WoUyOy7Pdr2uMICNVZd68ebRs2fK819esWUOFChWy3VdqaiqrV68mKCgoz3Fk1LZtWzZt2kRKSgqBgYHnLVu8eDELFy5k1apVlC9fnr59++Z6DX7myzPTngcFBaXvPyEhgbvuuov169fTsGFDpk6dWqBr+0uXLp3eTmBgYPqYijHFxcETZ3l4/mYWbT9Cp5AqdG1UsC94+VEkBouLqsGDB/P666+ndYXx66+/urXdpZdeyuuvv57+PC3BDBo0iDfeeCP99ePHjwPOh2VSUtIF+2natCldu3bl8ccfT48hOjqar7/+mpMnT1K1alXKly/Ptm3bWL16da5xrV27lj179pCamsrs2bO55JJLLlgn7UO/Ro0axMXFMXfu3PRlFStW5PTp0xdsEx4ezpIlSzh69CgpKSl8+umn9OnTJ9d4jCnqvth4gEtfXsrq3cd4bHgb5t5xEc1rV/R5HJYIvOjRRx8lKSmJ9u3b07ZtWx599FG3tnvttddYv3497du3p02bNulXID3yyCMcP36csLAwOnTowKJFiwCYMGEC7du3v2CwGJwrcw4dOkSzZs0ICwtj/Pjx1KpViyFDhpCcnEzr1q2ZMmUKPXr0yDWubt26MXHiRFq3bk3jxo0ZPXr0BetUqVKF2267jbCwMAYPHky3bt3Sl40fP5477rgjfbA4Td26dXnuuefo168fHTp0oEuXLowcOdKt98qYoqxyudJ0bFiFH+7vzc2XNCbQS1cF5abIzVnctWtXzTwxzW+//Ubr1q39FJEpTOxvwRRmySmpvLN8D0kpqUzs3xxwupB9cVe8iGxQ1a5ZLSsWReeMMaawizp4isnzItl84CTD2tdNTwCFoTSKJQJjjPGixOQU/vvzTt5cvIsq5Uvzv+s6MzSsTqFIAGksERhjjBdFH41n2pJdjOhYj0eHtaFqhTL+DukClgiMMcbDziQm82PUIUZ1qk/LOhX56R99Cale3t9hZcsSgTHGeNCyHUd48PPNHDhxlrD6lWhWq2KhTgJgicAYYzziZHwSz3wTxWfr99OkRgVmT+hJs1q+vycgP+w+Ag/JWIb68ssv58SJEzmuP3Xq1PTSE4899hgLFy7Mcf2MBdoyioiI4Lnnnstxn6+88kqey2KHhobSrl072rVrR5s2bXjkkUfSbxY7ePAgY8eOzdP+jCnOUlKVMdNWMu+XA9zVtynf3NuL8MZZl5ApjCwReEjGMtTVqlU77w7g3Dz55JMMHDgwX+2OGDGCKVOm5LjP/CQCcGoGbd68mbVr17J7925uv/12AOrVq3feHcMFkVPZamMKu2NnzpGaqgQGCJMGt+SLuy/mgSGtCCodmPvGhUjJTQQxa2HZi85vD+vZsycHDjgVtXft2sWQIUPo0qULvXr1Ytu2bResP378+PQP1qxKOKeZOXNm+lnH2rVO3O+//z4TJ07Mdp+vvfYaBw8epF+/fvTr1493332X++67L329GTNmcP/99+d4PMHBwUybNo0FCxZw7NgxoqOjCQsLA5ySFb169aJz58507tw5ff6C1NRU7rrrLlq1asWgQYO47LLL0o8xNDSUyZMn07lzZ+bMmcOMGTPo1q0bHTp0YMyYMelJa/z48dx555306NGDJk2asHjxYm6++WZat27N+PHj3fmnMMYrVJV5G/bT7z+LmbXOmV9rcNs6hNWv7OfI8qf4jRF8OwX+3JzzOomn4NAW0FSQAKgdBmUrZb9+nXYw9Dm3mk9JSeGnn37illtuAZzyD9OmTaN58+asWbOGu+66i59//jnb7SdOnMhjjz0GwA033MBXX32VXrkzPj6ejRs3snTpUm6++Wa2bNmSazz33HMPL730EosWLUqv//PMM8/wwgsvULp0ad577z3eeuutXPdTqVIlGjduzI4dO6hdu3b667Vq1eLHH38kKCiIHTt2MG7cONavX8/nn39OdHQ0UVFRHD58mNatW3PzzTenb1e9enV++eUXAGJjY7ntttsAp4zGO++8w9///nfAqae0atUqIiIiGDFiBCtWrODtt9+mW7dubNy4Mb3iqzG+sv94PA/N38LS34/QpVHVItUFlJ3ilwjckXDSSQLg/E44mXMicENaGeoDBw7QunVrBg0aRFxcHCtXruTKK69MXy8xMTHH/eRUwnncOKega+/evTl16lSu4xBZCQ4Opn///nz11Ve0bt2apKQk2rVr59a2WZUjSUpKYuLEiWzcuJHAwEB+//13AJYvX86VV15JQEAAderUoV+/fudtd/XVV6c/3rJlC4888ggnTpwgLi6OwYMHpy+7/PLLERHatWtH7dq102Nt27Yt0dHRlgiMT83/dT+PzN+CAk+MaMsNPRp5bdYwXyp+icCdb+4xa+GDEZByDgLLwJi3oWF4gZpNGyOIj49n8ODBvPHGG4wfP54qVapcUJ46O7mVcM6uDHRe3XrrrTz77LO0atWKm25ybxqI06dPEx0dTYsWLTh58mT66y+//DK1a9dm06ZNpKamul06O2MZ7vHjx7NgwQI6dOjA+++/z+LFi9OXlS1bFoCAgID0x2nPrSS18bVqFcrSJbQaz44Oo0HVwn1JaF6UzDGChuFwYwT0f9j5XcAkkFH58uV57bXXePHFFylfvjyNGzdmzpw5gPONetOmTdlum1MJZ4DZs2cDzrftypUrU7mye/2Rmcs/d+/enZiYGD755JP0s4ycxMXFcddddzFq1KgLJsM5efIkdevWJSAggJkzZ6YP/l588cXMmzeP1NRUDh06dN6He2anT5+mbt26JCUl8fHHH7t1TMb4QlJKKv9bvJPXftoBQJ8WNfngpm7FKglAcTwjcFfDcI8mgIw6depE+/bt+fTTT/n444+58847efrpp0lKSuKaa66hQ4cOWW6XsYRznTp1zivhDM4EMJ06dSIpKYl3333X7XgmTJjAkCFDqFevXnrp6quuuoqNGzfmOMtZv379UFVSU1MZPXp0lmW077rrLsaMGcOHH37IkCFD0r/pjxkzhp9++ok2bdrQsGFDOnfunG3ieuqpp+jevTs1a9ake/fuWc5ZYIyvbTlwksnzItl68BSXd6hXqIrEeZqVoS6hhg8fzv3338+AAQO81kZcXBzBwcHExsYSHh7OihUrqFPHu9Pv2d+CKaiEpBRe+2kHby3dTdXyZXh6VFuGhNX1d1gFZmWoTboTJ04QHh5Ohw4dvJoEwEk2J06c4Ny5czz66KNeTwLGeMLe2HhmLNvNFZ3q88iwNlQuX9rfIXmdJYISpkqVKulX9nhbTuMCxhQmZxKT+X7rn1zRuQEt61Tk53/2pWG14jUOkJNikwh8NcuPKbyKWjenKRyW/H6Ehz7fzMGTZ2nfoDLNalUsUUkAislVQ0FBQcTGxtoHQQmmqsTGxrp9+aoxx8+c4x+fbeTGd9cSVDqAObcXnSJxnlYszggaNGjA/v37OXLkiL9DMX4UFBREgwYN/B2GKQLSisTtjY1nYr9mTOzfrMjVB/KkYpEISpcuTePGjf0dhjGmkIuNS6Rq+TIEBghThrSiftVytK1XNOsDeVKx6BoyxpicqCqfrY+h338W8+m6fQBc2raOJQGXYnFGYIwx2Yk5Fs9D8zezbMdRwkOr0bNJdfc33r0UDqyD0F5euwG1MLBEYIwptj7/ZT+PLNiCAE+NCuO68BD3i8TtWAgfjwEESgV5vBxNYWKJwBhTbNUILkt442o8M7od9auUy9vGPz/leqBOgcroZZYIjDGmsEtKSeWtJbtISYV7Bzand4ua9G5RM+87il4Of2yEgFKg6lQpDu3l8XgLC0sExphiYcuBk0yaG8lvf5xiZMd6+b/JNDkRvrofqoTAiDdsjMAYYwq7hKQUXlm4gxnLdlOtQhneuqELg9sWoK7Vilfh6O9w3Txo0tv5Kea8evmoiAwRke0islNELphhXURCRGSRiPwqIpEicpk34zHGFD/7jsXzzvLdjO3cgIX39ylYEji6E5b+B8LGQPOBnguykPPaGYGIBAJvAIOA/cA6EYlQ1agMqz0CfKaqb4pIG+AbINRbMRljiofTCUl8t+VPruzakBa1K7LoX30LPlmMKnx1n3OF0OB/eyTOosKbXUPhwE5V3Q0gIrOAkUDGRKBA2mTBlYGDXozHGFMMLNp2mIfnb+bPUwl0CqlCs1oVPTNj2KZZzpVBw1+GirULvr8ixJuJoD4Qk+H5fqB7pnWmAj+IyN+BCkCW52IiMgGYABASEuLxQI0xhd+xM+d46qso5v96gOa1gpl750WeKxJ3Jha+fwgadofO4z2zzyLE34PF44D3VfVFEekJzBSRMFVNzbiSqk4HpoMzQ5kf4jTG+FFKqjL2zZXsOxbPPQOac3e/ppQt5cEicT8+ComnYPgrEFDyKu94MxEcABpmeN7A9VpGtwBDAFR1lYgEATWAw16MyxhTRBw5nUj1Ck6RuIcua039quVoXbdS7hvmxZ5lsPFjuOQfULuNZ/ddRHgz9a0DmotIYxEpA1wDRGRaZx8wAEBEWgNBgNWSNqaEU1Vmr9tH/xcX88lap0jcwDa1PZ8EkhOdAeKqodDnAc/uuwjx2hmBqiaLyETgeyAQeFdVt4rIk8B6VY0A/gnMEJH7cQaOx6vNLmNMibYvNp4pn0eyclcs3RtX45JmNbzX2LKXIHYnXP85lM5jCYpixKtjBKr6Dc4loRlfeyzD4yjgYm/GYIwpOuZu2M+jC7YQGCA8MzqMcd3yUCQur478DstfgnZXQrMB3mmjiPD3YLExxqSrXaksFzWtztOjw6hb2Yvf0FWdMhKly5e4ewayYonAGOM355JTeXPxLlJVuX9QC3o1r0mv5vkoEpdXGz+Gvcvh8tcg2AftFXKWCIwxfrEp5gQPzI1k+6HTXNGpfv6LxOXVmaPwwyMQ0hM63eD99ooASwTGGJ86ey6Fl37czjvL91CrYhBv/60rA9v48E7eHx6BxLgSe89AViwRGGN8KuZ4PB+s3Ms14SFMGdqKSkGlfdf47sWw6VPoPQlqtfJdu4WcJQJjjNedchWJu8pVJG7xpL7Uy+uMYQWVlOAMEFdrAr3+6du2CzlLBMYYr/p52yEe+nwLh08n0DmkKs1qBfs+CQAsexGO7Ya/fVGi7xnIiiUCY4xXxMYl8uRXUXyx8SAta1dk2g1daFYr2D/BbJ4Dy/4DTQdCk77+iaEQs0RgjPG4lFTlymmriDkez/0DW3Bn36aUKeWngdmdP8Hntzn3DuxdDjFri/W0k/lhicAY4zGHTydQo0JZAgOEh4e1pkHV8rSs46FS0flxaCvMu8VJAgApSc6cA5YIzmPXThljCiw1Vfl4zV76/2cJH7uKxA1oXdu/SSByDswYAAgElgUJhMAyzkT05jx2RmCMKZDoo2eY8nkkq3cf46Km1enjizuDc5J8zrlXYO1b0OhiGPsenNjrnAmE9rKzgSxYIjDG5Ntn62N4dMEWygQG8NwV7bi6W0Pf3B2cnVN/wJzxELMaek6EgVMhsLQz9aQlgGxZIjDG5Fv9KuXo3aImT40Mo07lIP8Gs3elkwQS42DsuxA2xr/xFCGWCIwxbktMTuF/i3ahqvzj0pZc3KwGF3tzvgB3qMLqN53uoGqNnfsEarX2b0xFjCUCY4xbft13nMnzIvn9UBxjOjfwXZG4nCTGwZf3wJZ50Go4jPofBFX2b0xFkCUCY0yO4s8l8+IPv/Puij3UqRTEu+O70r+VD4vEZefoTph9PRzdDgMeh0vuB38npiLKEoExJkcHjp9l5uq9XNc9hMlDWlHRl0XisrPta5h/BwSUcqaZbNrP3xEVaZYIjDEXOHk2iW83/8E14SE0r12RJZP6enfGMHelpsDPTztTTNbrBFfNhCoN/R1VkWeJwBhznh+2/skjC7YQe+YcXUOr0axWcOFIAmdiYd7NTinpzjfC0OehtJ+vVComLBEYYwA4GpfI1IitfBX5B63qVOTtG7v6r0hcZgc2wGc3QtxhGPE6dP6bvyMqViwRGGNISVXGvrmSgycS+NelLbi9T1NKBxaSCjQbPoBv/gXBteHm76B+Z39HVOxYIjCmBDt0KoGawU6RuMcvb0uDquVoXjsP9YH2roTo5U5pZ0/fuZuU4CSAX2dCk34w5h2oUN2zbRjAEoExJVJqqvLx2n3837fbmDykJTf0DKVfq1rZb6AKJ/bB4Sjn51AUHFgPx6Od5YuegXLVoEJN5zr+oMoQVCnD48pQNu15lQuXlQr669LPmLXw21ew/RuI3QG9/gX9HoKAQG+/LSWWJQJjSpjdR+KY8vlm1u45xiXNatC3ZaYEEH/MKd98OMr1+zfn59zpv9apHAKlygICqPO7aiOoEgIJpyA+1pkNLOGk85OalHNQAaWdhBBYFk4fdO0TGPgEXHKfx47dZM0SgTElQcxaiF7GwrPNuXtpacqWCuDF0c25osEZZO98WJfhQz/uz7+2K1cVarWFjuOcsg212jq/gyo5+/xgBKScc8o7D30+6+4hVUhO+CspJJx0kkXCib+eJ55yfsesgdMHnO0kEDTFJ29PSWeJwJjiLu0DOzmR/hJARHBbmgadptS3e0j/5l0qCGq2gqb9oXYbqOX6qVgn+7t1G4bDjRG5l3cWceYILl3O2Z87saYlF5s7wCcsERhTjCUmp7Dmx/n0Sj6LAAGaSsuAGKh7CXS8+q9v+dUa568PvmG4ZweJ3U0uxqMsERhTTG3Ye4wH5kYy8thBepcGRZBSZWHc7ML9Aevp5GJyZYnAmGLmTGIyL3y/nQ9WRdO74p/cHfQt1OyAtL4cmvSxD1lzAa/eMSIiQ0Rku4jsFJEp2axzlYhEichWEfnEm/EYUxIcPHGWT9bu47Zu1Xmvwn8JLFcVrp8LfSZZEjBZ8loiEJFA4A1gKNAGGCcibTKt0xx4ELhYVdsC93krHmOKs5PxSXyyxpk0vnntiiyb1JeHzr1OwMl9cNUHEJzDPQKmxPNm11A4sFNVdwOIyCxgJBCVYZ3bgDdU9TiAqh72YjzGZM11aWVRHZz8bsufPPrFFo6dOUf3JtVoWjOY2lumw7avYPC/IaSHv0M0hVyuiUBELge+VtXUPO67PhCT4fl+oHumdVq42lgBBAJTVfW7LGKYAEwACAkJyWMYxuQgZi28PwxSkpxLKG+MKDLJ4PDpBKZGbOWbzX/Spm4l3hvfjaY1g2HPMlg4FdqMgh53+jtMUwS40zV0NbBDRJ4XkVYebr8U0BzoC4wDZohIlcwrqep0Ve2qql1r1qzp4RBMiZWaAj896VyzjkJyonNmUASkpCpXTVvFwt8OM2lwS76YeDFh9SvD6T9h7s1QralTpdNm7DJuyPWMQFWvF5FKOB/U74uIAu8Bn6rq6Rw2PQBknDGigeu1jPYDa1Q1CdgjIr/jJIZ1eTgGY/Lu7HGYd5vzwZ9+B2sq1Ovi78hy9MfJs9SuGOQUiRvRloZVy/9VKjolCeaMh3NxzplNUCW/xmqKDrcGi1X1FDAXmAXUBUYDv4jI33PYbB3QXEQai0gZ4BogItM6C3DOBhCRGjhdRbvzEL8xeXcoCqb3cyY4GfYS3PQtdLnJWbZniV9Dy05qqvL+ij0MeHEJH63ZC0C/lrXOny9g4VTYtwouf825UcwYN7kzRjACuAloBnwIhKvqYREpjzPw+3pW26lqsohMBL7H6f9/V1W3isiTwHpVjXAtu1REooAUYJKqxnriwIzJ0pbP4Yu7oWxFGP81hLiGrUK6Q9JZWPVf6HQ9VG/q3zgz2Hk4jinzIlm/9zi9W9Skf1ZVQqO+cGIPnwDtr/R9kKZIE1XNeQWRD4B3VHVpFssGqOpP3gouK127dtX169f7sklTHKSmwE9PwIpXoUE4XPUhVKp7/jqn/4TXuzhXD107yz9xZjJr7T4ei9hKudKBPDa8DVd0ro9k7vc/uhOm94WaLZ2zm1Jl/BKrKdxEZIOqds1qmTuXj04F/siws3JAbVWN9nUSMCZf4o85A6i7F0HXm2HI/2X9YVmxDvR5AH58DHb8CM0H+T7WTEKql2dg61o8MSKMmhXLXrjCuTPw2Q0QWNq5X8CSgMkHd8YI5gAZLx1Ncb1mTOH3RyRM7wN7Vzh958NfzvnDsvudUL0ZfDsZks/5Lk6XhKQUnv9uG89/tw2Ai5rW4H/Xdck6CajCV/c7paPHvgOVG/g4WlNcuJMISqlq+v8I12P72mEKv8g58M6lkJLsGhC+MfdtSpWBIc/BsV2w5k3vx5jB+uhjXPbaMv63eBfHzpwjt25b1r8DkbOh38NO+Whj8smdRHDENWAMgIiMBI56LyRjCiglGb57CD6/Fep1gtuXQIMsu0az1nwQtBgKS553xg28LC4xmce/2MKVb63iXHIqH94cznNj2l84FpDR/g3w3YPQ/FLo9U+vx2iKN3cSwR3AQyKyT0RigMnA7d4Ny5h8OnMUZo6C1W9A+O3O9fT5qbMz+BnnRrMfH/d4iJn9efIss9bFcGPPUL6/rze9W+Ry0+SZWJhzIwTXgdFvQYBXa0eaEsCdG8p2AT1EJNj1PM7rURmTHwd/hVnXw5kjMOpN6Hht/vdVvSn0nAjLX3IGmEMyV0cpmONnzvHV5j+4oUcjmtWqyLIH+lGrUlDuG6amOGc6cYfglh+gfDWPxmVKJreKzonIMKAtEJR2uqqqT3oxLmPyZuMn8OV9zrf/W753uoQKqtc/YdMs+PYBuO3n/M3glYmq8u2WP3nsiy2ciE/ioqbVaVoz2L0kAE531a6f4fJXPXOMxuBG15CITMOpN/R3QIArgUZejssY96QkwTeTYMGdTrG4CYs99wFZNhgufQr+2Ai/zizw7g6fSuCOjzZw18e/ULdyOSImXuIUiXPXjoWw5P+gw7XQ2Y2Bb2Pc5E7n4kWq+jfguKo+AfTEVTXUGL+KO+xMdL52utONc8MCqFDDs22EjYGQnk5xurPH872blFTlyrdWsXj7ER4c2or5d11Em3p5qAV0Yp/TJVS7LQx70YrJGY9yp2sowfU7XkTqAbE49YaM8Z/962H2Dc6H8xVve6+sgggMfd65F2HxczD0//K0+cETZ6lTySkS9+TIMBpWLUeTvJwFgFMV9bO/OeMDV30IZcrnbXtjcuHOGcGXrtLQLwC/ANGATSlp/OeXD+G9oc7dtLf+6P3aOnXbO0Xp1s5wCta5ISVVeS9Tkbg+LWrmPQkAfDfFGQgfPa1Q1UAyxUeOZwQiEgD8pKongHki8hUQpKonfRGcMedJTnTu+N3wHjTpB2Pf9d1VM/0fgS3znIHjG7/MsWtm5+HTPDA3kl/2naBvy5oMaF07/+1umgXr34WL74VWw/K/H2NykGMiUNVUEXkD6OR6nggk+iIwY9LFrIXt38D27+DIb3DxfTDgMY9cxeO28tWcZPDNv5xKn21HZbnaJ2v2MTViKxXKBvLy1R0Y1TGLInHu2jTLqZRapz30fyz/sRuTC3fGCH4SkTHA55rrPe/GeFjMWvhguHM2AM6Hce9J/oml682w4QP44RHnjt4s+upDa5Tn0ra1mTqiLTWCs6gP5K4NH8KX9wAKR3+Hg78UmSk0TdHjzhjB7ThF5hJF5JSInBaRU16OyxhH9LK/koAEOD/+EhDoDBafjIEVrwBOkbh/f/sbz337V5G4/17bOf9J4OCv8PFV8OXfAdf3rpSkIjOFpima3LmzuKIvAjEmS2Urux4IBJZ15grwp9CLnUtKl7/CxmqXcf+PJ9hz9AzXdQ9BVfPfDfTHJueqpO3fQFAV6HoTbPzUSQKBZfx/3KZYc2eGst5ZvZ7VRDXGeJQqbJkL5as7dYOa9isU3SNxvR+nTNTX/DH3X6RUfJhPbu3ORc3yef/Cn1tg8b9h21cQVBn6PQLdb3fmG+5wrXMmENqrUBy3Kb7cGSPI2CEbBIQDGwCre2u8a+dCZw7eYS9Bt1v8HU26P6nOl8kjuT9wNv1GphCUnyRwKAqWPOcMPJetBH0fhO53QLkqf63TMNwSgPGJXKeqvGADkYbAK6o6xjsh5cymqiwhUlOdm7gST8Hd6/w+89axM+f4OvIgN/QMBeDI8ZPU/LC301115wrnngZ3HNnudAFtnQ9lgqHHndDzLihX1XvBG0PBp6rMbD/QumAhGZOL376APyNh9HS/JgFV5avIP5gasZVTCUlc3KwGTWoGU7NqZRj8b5g1zrnRrOddOe/o6A6nTtDmuVC6PPT6h1MWw6qHmkLAnTGC10m/fIEAoCPOHcbGeEdKMvz8DNRsDe3G+i2MQ6cSeHj+Fhb+doj2DSrz8dju598Z3HIoNBvo9PG3uxKCs5hHIHaXUzF082dQKsi5Meyie6BCdd8diDG5cOeMIGM/TDLwqaqu8FI8xkDkLIjdAVd/7NubxjJISVWuemsVf55M4OHLWnPTxaGUCsx06aqIM63l/3rAT1Nh5Bt/LTu2B5a+4NwUFlgGet4NF92bdbIwxs/cSQRzgQRVTQEQkUARKa+q8d4NzZRIyYlOH3q9zn4pqbD/eDx1K5cjMEB4amQYIdXKE1qjQvYb1Gju9POvfB0Cg6BJH9jxA2z6FAJKOQPAF98LFQtQZsIYL3Pn7pyfgHIZnpcDFnonHFPibXjfuWFrwGM+LbWckqq8vWw3A19awkernSJxvVvUzDkJpGk6wPm9/m347AbnLKDbrXDvJhjyrCUBU+i5c0YQlHF6SlWNExGrg2s879wZpzsltBc06euzZrf/eZoH5kWyKeYEA1rV4tK2efzgPvgLzpxN6vzueTcMesILkRrjHe4kgjMi0llVfwEQkS7AWe+GZUqkNdOc+Yav+cRnZwMfrd7LE19upWJQaV69piMjOtTL+93Bob2cgeCUc854gFUJNUWMO4ngPmCOiBzE+dpTB2fqSmM85+xxWPEqtBjqk5uo0spBNKsVzGXt6vLY8DZUz299oIbhcGOE3QVsiix3ag2tE5FWQEvXS9tVNcm7YZkSZ+XrkHDSqS7qRWfPpfDSj9sJCBAeHNqaHk2q06OJBy7ltLuATRHmzuT1dwMVVHWLqm4BgkUkl7tnjMmDuMOw+k0IGwt1wrzWzKpdsQx5dSkzlu0hPjEFq6pujMOdq4Zuc81QBoCqHgdu81pEpuRZ9qJz2Wi/h7yy+1MJSTz4+WbGzVgNwCe3deepUWH5rxRqTDHjzhhBoIhI2qQ0IhII+Lfwiyk+TuxzpmLsdL3X5uM9fCqRBb8eYELvJtw/sAXlyvjnJjVjCit3zgi+A2aLyAARGQB8Cnzrzs5FZIiIbBeRnSIyJYf1xoiIikiWBZFMMbb4/wCBPg94dLexcYm8v2IPAM1qBbN8cj8euqy1JQFjsuDOGcFkYAJwh+t5JM6VQzlynTm8AQzCKVS3TkQiVDUq03oVgXuBNXmI2xQHR36HTZ9A9zuhcgOP7FJVidh0kKkRW4lLTKZ3i5o0qRmc/yuCjCkBcj0jUNVUnA/paJy5CPoDv7mx73Bgp6ruVtVzwCxgZBbrPQX8H5DgZsymuFj0zF+VOD3g4Imz3PLBeu6dtZFG1Svw9T29zi8SZ4zJUrZnBCLSAhjn+jkKzAZQ1X5u7rs+EJPh+X6ge6Y2OgMNVfVrEcl2RnIRmYBzVkJISIibzZtC7eBGiFoAfSZDhXzO7pVBckoq10xfzZHTiTw6vA3jLwolMMAGg41xR05dQ9uAZcBwVd0JICL3e6phEQkAXgLG57auqk4HpoMzMY2nYjB+9PPTzmQsPe8u0G5ijsVTr0o5SgUG8OzodoRUK09IdauAYkxe5NQ1dAXwB7BIRGa4Borz8hXrANAww/MGrtfSVATCgMUiEg30ACJswLgE2LsSdv4Il9zvzNObD8kpqUxfuouBLy1h5qpoAC5pXsOSgDH5kO0ZgaouABaISAWcvv37gFoi8iYwX1V/yGXf64DmItIYJwFcA1ybYf8ngfQ+ARFZDPxLVW0eyuJMFX56EoLrQLf83Y7y2x+nmDwvksj9JxnUpjZD29X1cJDGlCzulJg4A3wCfCIiVYErca4kyjERqGqyiEwEvgcCgXdVdauIPAmsV9WIAkdvip6dP7kmpH8RyuT92/vMVdE88WUUlcuV5r/XdmJYu7p2Y5gxBZTnyev9zSavL8LSJqRPOAkT1+dpLuK0InFrdscya10Mjw5vQ7UKdl+jMe7y9OT1xuTPbxGuCenfcjsJxJ9L5j/f/06pQOGhy1rTvUl1unuiSJwxJp07dxYbU3Apyc59AzVbORO9u2HFzqMMfmUp767Yw7nkVCsSZ4yX2BmB8Y3I2XD0d7j6o1wnpD95Nolnv/6N2etjaFyjAp/d3pPwxtV8FKgxJY8lAuN96RPSd4JWw3Nd/WhcIl9GHuSOPk25b2BzgkpbfSBjvMkSgfG+DR/AyX0w4tVsp6A8cjqRLzcd5OZLGtO0ZjDLJ/e3wWBjfMQSgfGu3Utg4VSo0wGaXFidRFVZsPEAT3wZRXxiCv1a1aJxjQqWBIzxIUsExnti1sJHV0BqMhzZBvvXnTed44ETZ3l4/mYWbz9C55AqPD+2PY1rVPBjwMaUTJYIjPdEL4PUFOdxarLz3JUInCJxq4iNO8fUy9twQ08rEmeMv1giMN4T2gtKBUHKOQgsA6G92BcbT/2qTpG4565oT0i18jSsZvWBjPEnSwTGexqGw40REL2M5JCLmbGrOi8vXMKDQ1tx08WNubhZwctPG2MKzhKB8a6G4WwNbMnkeZFsObCNwW1rM8yKxBlTqFgiMF71wcponvoqiirly/DmdZ2tUqgxhZAlAuMVaUXiWtWpyMiO9Xl0eGuqlLdLQo0pjCwRGI86k5jMC99vp3Sg8PCwNlYkzpgiwIrOGY9Z+vsRLn15KR+siiYpRa1InDFFhJ0RmAI7GZ/EU19HMXfDfprUdIrEdQu1InHGFBWWCEyBHT2TyLeb/+Cuvk25Z4AViTOmqLFEYPLl8OkEIjYe5NZeTdKLxFW1+kDGFEmWCEyeqCrzfjnAU19FcTYphQGta9O4RgVLAsYUYZYIjNtijsXz0PzNLNtxlK6NqvLcGCsSZ0xxYInAuCU5JZVxM1Zz/Mw5nhrZluu6NyLAisQZUyxYIjA5ij56hobVylMqMIDnxzpF4hpUtSJxxhQndh+ByVJSSipvLNrJpS8v5cNV0QBc1LSGJQFjiiE7IzAX2HLgJA/MjSTqj1MMa1eX4e3r+TskY4wXWSIw53lvxR6e/vo3qlUow7TruzAkrI6/QzLGeJklAgP8VSSubb3KXNGpPo8Ma0Pl8qX9HZYxxgcsEZRwcYnJPP/dNsoEBvDI8DaEN65GeGMrD2FMSWKDxSXY4u2HGfzyUmau3ouCFYkzpoSyM4IS6PiZczz1dRSf/3KAZrWCmXvHRXRpVNXfYRlj/MQSQQl0PP4cP2w9xD39m3F3/2aULWVF4owpybzaNSQiQ0Rku4jsFJEpWSz/h4hEiUikiPwkIo28GU9JdvhUAtOX7kJVaVIzmBWT+/OPS1taEjDGeC8RiEgg8AYwFGgDjBORNplW+xXoqqrtgbnA896Kp6RSVT5bF8OAl5bw4g+/Ex0bD2BXBBlj0nmzaygc2KmquwFEZBYwEohKW0FVF2VYfzVwvRfjKXFijsXz4OebWb7zKOGNq/HcFe2sSJwx5gLeTAT1gZgMz/cD3XNY/xbg26wWiMgEYAJASEiIp+Ir1tKKxJ2IT+LpUWFcGx5iReKMMVkqFIPFInI90BXok9VyVZ0OTAfo2rWrXeOYgz1HzxDiKhL3wtgONKpennpVyvk7LGNMIebNweIDQMMMzxu4XjuPiAwEHgZGqGqiF+Mp1pJSUnn9px0MfnkpH6yMBqBn0+qWBIwxufLmGcE6oLmINMZJANcA12ZcQUQ6AW8BQ1T1sBdjKdYi95/ggbmRbPvzNJd3qMeIjlYkzhjjPq8lAlVNFpGJwPdAIPCuqm4VkSeB9aoaAbwABANzRARgn6qO8FZMxdG7y/fw9NdR1KxYlhl/68qgNrX9HZIxpojx6hiBqn4DfJPptccyPB7ozfaLs7Qice0bVObqbg2ZMrQ1lcvZJaHGmLwrFIPFxn2nE5J47tttlC0VyGOXt6FraDW6hlqROGNM/lnRuSJk0bbDXPryUj5du49SgWJF4owxHmFnBEXAsTPnePLLrSzYeJAWtYP533UX0SnEisQZYzzDEkERcPJsEj/9dph7BzTn7n7NKFPKTuSMMZ5jiaCQ+vNkAgs2HuD23k1oXKMCy6f0t8FgY4xXWCIoZFSVWetiePbr30hKTWVI2zqE1qhgScAY4zWWCAqRvbFnmDJvM6t2x9KjSTWeu6I9oVYkzhjjZZYIConklFSunbGGk2eTeHZ0O67p1tCKxBljfMISgZ/tOhJHI1eRuBevcorE1a1s9YGMMb5jl5/4ybnkVF5Z+DtDXlnKh6v2AtCjSXVLAsYYn7MzAj/YGHOCyXMj2X7oNCM71mNUp/r+DskYU4JZIvCxd5bv4Zmvo6hVMYh3buzKgNZWJM4Y41+WCHwkrUhcx4aVuSY8hClDW1EpyC4JNcb4nyUCLzuVkMS/v9lGUOkAHr+8LV0aVaNLIysSZ4wpPGyw2IsWRh1i0EtLmL1uH2VKBViROGNMoWRnBF4QG5fIE19GEbHpIK3qVGT6DV3p0LCKv8MyxpgsWSLwgtMJySzafpj7B7bgzr5NrUicMaZQs0TgIQdPnGX+rwe4q29TQmtUYMWU/jYYbIwpEiwRFFBqqvLJ2n089+02UlKVYe3qElqjgiUBY0yRYYmgAPYcPcOUeZGs2XOMi5tV59+j2xNSvby/wzLGmDyxRJBPySmpXP/2Gk4lJPH8mPZc2bUBIlYkzhhT9FgiyKOdh08TWr0CpQIDePnqjjSqXp7alYL8HZYxxuSbXc7ipsTkFF768XeGvLKMD1xF4sIbV7MkYIwp8uyMwA2/7DvO5LmR7DgcxxWd6nOFFYkzxhQjlghyMWPpbp799jfqVgrivZu60a9lLX+HZIwxHmWJIBupqUpAgNC5URWu6x7C5CGtqGiXhBpjiiFLBJmcPJvEM19HUa50IE+MDLMiccaYYs8GizP4fuufDHppCfN+OUCFsqWsSJwxpkSwMwLgaFwij3+xla83/0GbupV4d3w3wupX9ndYxhjjE5YIgLiEZJbtOMKkwS2Z0LsJpQPtRMkYU3KU2ERw4MRZ5v+yn7v7NSO0RgVWPjiA4LIl9u0wxpRgXv3qKyJDRGS7iOwUkSlZLC8rIrNdy9eISKg34wHnaqCZq6K59KUlvLFoF3tj4wEsCRhjSiyvffqJSCDwBjAI2A+sE5EIVY3KsNotwHFVbSYi1wD/B1ztrZh2HYnjwXmbWRt9jF7Na/Ds6HY0rGZF4owxJZs3vwaHAztVdTeAiMwCRgIZE8FIYKrr8VzgvyIi6oXLdZJTUvnbO2s5nZDEC2PbM7aLFYkzxhjwbiKoD8RkeL4f6J7dOqqaLCIngerA0YwricgEYAJASEhIvoIpFRjAK9d0pFG18tSy+kDGGJOuSFweo6rTVbWrqnatWbNmvvfTLbSaJQFjjMnEm4ngANAww/MGrteyXEdESgGVgVgvxmSMMSYTbyaCdUBzEWksImWAa4CITOtEADe6Ho8FfvbG+IAxxpjseW2MwNXnPxH4HggE3lXVrSLyJLBeVSOAd4CZIrITOIaTLIwxxviQVy+eV9VvgG8yvfZYhscJwJXejMEYY0zOisRgsTHGGO+xRGCMMSWcJQJjjCnhLBEYY0wJJ0Xtak0ROQLszefmNch017IP+attO+bi364/27ZjLjptN1LVLO/ILXKJoCBEZL2qdi1JbdsxF/92/dm2HXPxaNu6howxpoSzRGCMMSVcSUsE00tg23bMxb9df7Ztx1wM2i5RYwTGGGMuVNLOCIwxxmRiicAYY0q4YpkIRGSIiGwXkZ0iMiWL5WVFZLZr+RoRCfVRu71F5BcRSRaRsZ5oMw9t/0NEokQkUkR+EpFGPmr3DhHZLCIbRWS5iLTxRLvutJ1hvTEioiLikcvu3Djm8SJyxHXMG0XkVk+0607brnWucv1bbxWRT3zRroi8nOF4fxeRE55o1822Q0RkkYj86vr7vsxH7TZy/V+KFJHFItLAQ+2+KyKHRWRLNstFRF5zxRUpIp0L3KiqFqsfnJLXu4AmQBlgE9Am0zp3AdNcj68BZvuo3VCgPfAhMNbHx9wPKO96fKcPj7lShscjgO98dcyu9SoCS4HVQFcfHfN44L9++ttuDvwKVHU9r+Wr9zrD+n/HKTvvq2OeDtzpetwGiPZRu3OAG12P+wMzPXTMvYHOwJZsll8GfAsI0ANYU9A2i+MZQTiwU1V3q+o5YBYwMtM6I4EPXI/nAgOk4DPZ59quqkaraiSQWsC28tP2IlWNdz1djTNjnC/aPZXhaQXAU1cnuPPvDPAU8H9Ago/b9QZ32r4NeENVjwOo6mEftZvROOBTD7TrbtsKVHI9rgwc9FG7bYCfXY8XZbE8X1R1Kc78LNkZCXyojtVAFRGpW5A2i2MiqA/EZHi+3/ValuuoajJwEqjug3a9Ja9t34LzjcIn7YrI3SKyC3geuMcD7brVtuuUuaGqfu2hNt1q12WM67R9rog0zGK5t9puAbQQkRUislpEhvioXcDpLgEa89cHpC/angpcLyL7ceY/+buP2t0EXOF6PBqoKCIF/RzxVGx5UhwTgcmBiFwPdAVe8FWbqvqGqjYFJgOP+KJNEQkAXgL+6Yv2MvkSCFXV9sCP/HX26QulcLqH+uJ8M58hIlV82P41wFxVTfFhm+OA91W1AU63yUzXv7+3/QvoIyK/An1w5mD35XF7THFMBAeAjN/AGrhey3IdESmFczoZ64N2vcWttkVkIPAwMEJVE33VbgazgFEeaNedtisCYcBiEYnG6UuN8MCAca7HrKqxGd7ft4EuBWzT7bZxvh1GqGqSqu4BfsdJDN5uN801eK5byN22bwE+A1DVVUAQTnE2r7arqgdV9QpV7YTz/wpVPVHAdj0SW555YnCjMP3gfCPajXN6mjbI0zbTOndz/mDxZ75oN8O67+PZwWJ3jrkTzuBXcx+32zzD48tx5qv2SduZ1l+MZwaL3TnmuhkejwZW+/D9HgJ84HpcA6cLobov3mugFRCN60ZVHx7zt8B41+PWOGMEBYrBzXZrAAGux88AT3rwuEPJfrB4GOcPFq8tcHueCrww/eCcHv7u+uB72PXakzjfhMH5xjAH2AmsBZr4qN1uON/YzuCcgWz14TEvBA4BG10/ET5q91Vgq6vNRVl9gHir7UzrLsYDicDNY/6365g3uY65lQ//nQWnSywK2Axc46v3Gqev/jlPHWsejrkNsML1fm8ELvVRu2OBHa513gbKeqjdT4E/gCTX58UtwB3AHRn+jd9wxbXZE3/XVmLCGGNKuOI4RmCMMSYPLBEYY0wJZ4nAGGNKOEsExhhTwlkiMMaYEs4SgSn2RKSOiMwSkV0iskFEvhGRFvnYTy9XRc+NIlJfROZms95iT1U6NcYXLBGYYs1VTHA+sFhVm6pqF+BBoHY+dncd8G9V7aiqB1TVo6XEjfEXSwSmuOsHJKnqtLQXVHUTsFxEXhCRLa75Eq4GEJG+rm/0c0Vkm4h87Kr/fitwFfCU67XQtHrxIlLOdcbxm4jMB8qltSUil4rIKnHmoZgjIsGu16NF5AnX65tFpJXr9WARec/1WqSIjMlpP8Z4giUCU9yFARuyeP0KoCPQARgIvJChlG8n4D6cO1abABer6ttABDBJVa/LtK87gXhVbQ08jqu2kIjUwCmyN1BVOwPrgX9k2O6o6/U3cQqYATwKnFTVduoUrfvZjf0YUyCl/B2AMX5yCfCpOlUyD4nIEpwSIKdwarfsBxCRjTh1X5bnsK/ewGsAqhopIpGu13vgKn/gmu6iDLAqw3afu35v4K9yxgNx6l/h2t9xERmey36MKRBLBKa424pTEyYvMlZmTSH//08E+FFVx+XSTm5t5LYfYwrEuoZMcfczUFZEJqS9ICLtgRPA1SISKCI1cb7Vr81nG0uBa137DsOZjhScmeAuFpFmrmUV3Lha6Uec6rhpsVbN536McZslAlOsqVNVcTQw0HX56Fac6qCfAJE4FSt/Bh5Q1T/z2cybQLCI/IZTnXKDq+0jOPMXf+rqLlqFU6o5J08DVV2D2JuAfvncjzFus+qjxhhTwtkZgTHGlHCWCIwxpoSzRGCMMSWcJQJjjCnhLBEYY0wJZ4nAGGNKOEsExhhTwv0/nWW+T6EZJ+4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def ece_eval(preds, targets, n_bins=15, bg_cls = -1):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    confidences, predictions = np.max(preds,1), np.argmax(preds,1)\n",
    "    confidences, predictions = confidences[targets>bg_cls], predictions[targets>bg_cls]\n",
    "    accuracies = (predictions == targets[targets>bg_cls]) \n",
    "    Bm, acc, conf = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
    "    ece = 0.0\n",
    "    bin_idx = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = np.logical_and(confidences > bin_lower, confidences <= bin_upper)\n",
    "        #in_bin = in_bin[targets>backgound_class]\n",
    "        bin_size = np.sum(in_bin)\n",
    "        \n",
    "        Bm[bin_idx] = bin_size\n",
    "        if bin_size > 0:  \n",
    "            accuracy_in_bin = np.sum(accuracies[in_bin])\n",
    "            acc[bin_idx] = accuracy_in_bin / Bm[bin_idx]\n",
    "            confidence_in_bin = np.sum(confidences[in_bin])\n",
    "            conf[bin_idx] = confidence_in_bin / Bm[bin_idx]\n",
    "        bin_idx += 1\n",
    "        \n",
    "    ece_all = Bm * np.abs((acc - conf))/ Bm.sum()\n",
    "    ece = ece_all.sum() \n",
    "    return ece, acc, conf, Bm\n",
    "\n",
    "\n",
    "def get_reliability_diagram(conf_avg, acc_avg, legend=None, leg_idx=0, n_bins=10, fig=2):\n",
    "    plt.figure(fig)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--',label = 'Perfect Calibration')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(0, 1.1, 1/n_bins))\n",
    "    plt.title('{}'.format(fig))\n",
    "    plt.plot(conf_avg[acc_avg>0],acc_avg[acc_avg>0], marker='.', label = legend)\n",
    "    plt.legend()\n",
    "    plt.savefig('ece_reliability_diag_{}.png'.format(fig),dpi=300)\n",
    "    \n",
    "logits_all =F.softmax(logits_all, dim=1).detach().cpu().numpy()\n",
    "labels_all =labels_all.detach().cpu().numpy()\n",
    "ece, acc, conf, Bm = ece_eval(logits_all, labels_all)\n",
    "get_reliability_diagram(conf, acc, legend='Reliability Diagram', fig='reliability_diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfce18ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.30820998 0.3648994\n",
      " 0.44333113 0.49971373 0.56610034 0.63114371 0.70183264 0.77236199\n",
      " 0.83947441 0.88508748 0.        ] <class 'numpy.ndarray'>\n",
      "[0.         0.         0.         0.         0.33333333 0.5\n",
      " 0.59615385 0.44827586 0.5        0.62962963 0.64864865 0.64197531\n",
      " 0.72289157 0.83505155 0.        ] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(conf, type(conf))\n",
    "print(acc,type(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bc8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
