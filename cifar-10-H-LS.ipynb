{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93e3009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/cifar-10h\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/jcpeterson/cifar-10h\n",
    "%cd cifar-10h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409ba526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import argparse\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "def seed_everything(seed=12):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "parser = argparse.ArgumentParser(description='CIFAR-10H Training')\n",
    "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
    "parser.add_argument('--batch_size', default=1024, type=int, help='batch size')\n",
    "parser.add_argument('--test_batch_size', default=2048, type=int, help='batch size')\n",
    "parser.add_argument('--num_epoch', default=100, type=int, help='epoch number')\n",
    "parser.add_argument('--num_classes', type=int, default=10, help='number classes')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585d2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets, ad) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets,conf_score)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b4048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "class CIFAR10H(torchvision.datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root,  rand_number=0, train=False, transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        super(CIFAR10H, self).__init__(root, train, transform, target_transform, download) \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.ad = np.load(os.path.join(root,'cifar10h-probs.npy'))\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "        ad = self.ad[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target, ad\n",
    "\n",
    "class CELossWithLS(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, classes= args.num_classes, smoothing=0.16, ignore_index=-1):\n",
    "        super(CELossWithLS, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.complement = 1.0 - smoothing\n",
    "        self.cls = classes\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, logits, target, conf_score):\n",
    "        with torch.no_grad():\n",
    "#             new_smoothing  = self.smoothing - conf_score/10\n",
    "#             new_complement = 1 - new_smoothing\n",
    "            oh_labels = F.one_hot(target.to(torch.int64), num_classes = self.cls).contiguous()\n",
    "            smoothen_ohlabel = oh_labels * self.complement + self.smoothing / self.cls\n",
    "        \n",
    "        logs = self.log_softmax(logits[target!=self.ignore_index])\n",
    "        return -torch.sum(logs * smoothen_ohlabel[target!=self.ignore_index], dim=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce9466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train samples: 10000 test samples: 50000\n",
      "epoch: 0  acc: 0.4131  best epoch: 0  best acc: 0.4131\n",
      "epoch: 1  acc: 0.5457  best epoch: 1  best acc: 0.5457\n",
      "epoch: 2  acc: 0.6626  best epoch: 2  best acc: 0.6626\n",
      "epoch: 3  acc: 0.7216  best epoch: 3  best acc: 0.7216\n",
      "epoch: 4  acc: 0.7369  best epoch: 4  best acc: 0.7369\n",
      "epoch: 5  acc: 0.7540  best epoch: 5  best acc: 0.7540\n",
      "epoch: 6  acc: 0.7484  best epoch: 5  best acc: 0.7540\n",
      "epoch: 7  acc: 0.7353  best epoch: 5  best acc: 0.7540\n",
      "epoch: 8  acc: 0.7648  best epoch: 8  best acc: 0.7648\n",
      "epoch: 9  acc: 0.7681  best epoch: 9  best acc: 0.7681\n",
      "epoch: 10  acc: 0.7638  best epoch: 9  best acc: 0.7681\n",
      "epoch: 11  acc: 0.7674  best epoch: 9  best acc: 0.7681\n",
      "epoch: 12  acc: 0.7694  best epoch: 12  best acc: 0.7694\n",
      "epoch: 13  acc: 0.7779  best epoch: 13  best acc: 0.7779\n",
      "epoch: 14  acc: 0.7525  best epoch: 13  best acc: 0.7779\n",
      "epoch: 15  acc: 0.7595  best epoch: 13  best acc: 0.7779\n",
      "epoch: 16  acc: 0.7792  best epoch: 16  best acc: 0.7792\n",
      "epoch: 17  acc: 0.7838  best epoch: 17  best acc: 0.7838\n",
      "epoch: 18  acc: 0.7744  best epoch: 17  best acc: 0.7838\n",
      "epoch: 19  acc: 0.7795  best epoch: 17  best acc: 0.7838\n",
      "epoch: 20  acc: 0.7817  best epoch: 17  best acc: 0.7838\n",
      "epoch: 21  acc: 0.7567  best epoch: 17  best acc: 0.7838\n",
      "epoch: 22  acc: 0.7723  best epoch: 17  best acc: 0.7838\n",
      "epoch: 23  acc: 0.7483  best epoch: 17  best acc: 0.7838\n",
      "epoch: 24  acc: 0.7531  best epoch: 17  best acc: 0.7838\n",
      "epoch: 25  acc: 0.7596  best epoch: 17  best acc: 0.7838\n",
      "epoch: 26  acc: 0.7649  best epoch: 17  best acc: 0.7838\n",
      "epoch: 27  acc: 0.7630  best epoch: 17  best acc: 0.7838\n",
      "epoch: 28  acc: 0.7682  best epoch: 17  best acc: 0.7838\n",
      "epoch: 29  acc: 0.7736  best epoch: 17  best acc: 0.7838\n",
      "epoch: 30  acc: 0.7952  best epoch: 30  best acc: 0.7952\n",
      "epoch: 31  acc: 0.8029  best epoch: 31  best acc: 0.8029\n",
      "epoch: 32  acc: 0.8034  best epoch: 32  best acc: 0.8034\n",
      "epoch: 33  acc: 0.8051  best epoch: 33  best acc: 0.8051\n",
      "epoch: 34  acc: 0.8061  best epoch: 34  best acc: 0.8061\n",
      "epoch: 35  acc: 0.8061  best epoch: 34  best acc: 0.8061\n",
      "epoch: 36  acc: 0.8079  best epoch: 36  best acc: 0.8079\n",
      "epoch: 37  acc: 0.8085  best epoch: 37  best acc: 0.8085\n",
      "epoch: 38  acc: 0.8087  best epoch: 38  best acc: 0.8087\n",
      "epoch: 39  acc: 0.8082  best epoch: 38  best acc: 0.8087\n",
      "epoch: 40  acc: 0.8065  best epoch: 38  best acc: 0.8087\n",
      "epoch: 41  acc: 0.8070  best epoch: 38  best acc: 0.8087\n",
      "epoch: 42  acc: 0.8073  best epoch: 38  best acc: 0.8087\n",
      "epoch: 43  acc: 0.8076  best epoch: 38  best acc: 0.8087\n",
      "epoch: 44  acc: 0.8078  best epoch: 38  best acc: 0.8087\n",
      "epoch: 45  acc: 0.8072  best epoch: 38  best acc: 0.8087\n",
      "epoch: 46  acc: 0.8077  best epoch: 38  best acc: 0.8087\n",
      "epoch: 47  acc: 0.8078  best epoch: 38  best acc: 0.8087\n",
      "epoch: 48  acc: 0.8089  best epoch: 48  best acc: 0.8089\n",
      "epoch: 49  acc: 0.8088  best epoch: 48  best acc: 0.8089\n",
      "epoch: 50  acc: 0.8094  best epoch: 50  best acc: 0.8094\n",
      "epoch: 51  acc: 0.8082  best epoch: 50  best acc: 0.8094\n",
      "epoch: 52  acc: 0.8079  best epoch: 50  best acc: 0.8094\n",
      "epoch: 53  acc: 0.8084  best epoch: 50  best acc: 0.8094\n",
      "epoch: 54  acc: 0.8088  best epoch: 50  best acc: 0.8094\n",
      "epoch: 55  acc: 0.8093  best epoch: 50  best acc: 0.8094\n",
      "epoch: 56  acc: 0.8098  best epoch: 56  best acc: 0.8098\n",
      "epoch: 57  acc: 0.8084  best epoch: 56  best acc: 0.8098\n",
      "epoch: 58  acc: 0.8086  best epoch: 56  best acc: 0.8098\n",
      "epoch: 59  acc: 0.8094  best epoch: 56  best acc: 0.8098\n",
      "epoch: 60  acc: 0.8100  best epoch: 60  best acc: 0.8100\n",
      "epoch: 61  acc: 0.8100  best epoch: 60  best acc: 0.8100\n",
      "epoch: 62  acc: 0.8100  best epoch: 62  best acc: 0.8100\n",
      "epoch: 63  acc: 0.8101  best epoch: 63  best acc: 0.8101\n",
      "epoch: 64  acc: 0.8098  best epoch: 63  best acc: 0.8101\n",
      "epoch: 65  acc: 0.8100  best epoch: 63  best acc: 0.8101\n",
      "epoch: 66  acc: 0.8104  best epoch: 66  best acc: 0.8104\n",
      "epoch: 67  acc: 0.8099  best epoch: 66  best acc: 0.8104\n",
      "epoch: 68  acc: 0.8101  best epoch: 66  best acc: 0.8104\n",
      "epoch: 69  acc: 0.8100  best epoch: 66  best acc: 0.8104\n",
      "epoch: 70  acc: 0.8104  best epoch: 66  best acc: 0.8104\n",
      "epoch: 71  acc: 0.8100  best epoch: 66  best acc: 0.8104\n",
      "epoch: 72  acc: 0.8099  best epoch: 66  best acc: 0.8104\n",
      "epoch: 73  acc: 0.8100  best epoch: 66  best acc: 0.8104\n",
      "epoch: 74  acc: 0.8103  best epoch: 66  best acc: 0.8104\n",
      "epoch: 75  acc: 0.8104  best epoch: 75  best acc: 0.8104\n",
      "epoch: 76  acc: 0.8105  best epoch: 76  best acc: 0.8105\n",
      "epoch: 77  acc: 0.8098  best epoch: 76  best acc: 0.8105\n",
      "epoch: 78  acc: 0.8101  best epoch: 76  best acc: 0.8105\n",
      "epoch: 79  acc: 0.8101  best epoch: 76  best acc: 0.8105\n",
      "epoch: 80  acc: 0.8099  best epoch: 76  best acc: 0.8105\n",
      "epoch: 81  acc: 0.8098  best epoch: 76  best acc: 0.8105\n",
      "epoch: 82  acc: 0.8100  best epoch: 76  best acc: 0.8105\n",
      "epoch: 83  acc: 0.8101  best epoch: 76  best acc: 0.8105\n",
      "epoch: 84  acc: 0.8100  best epoch: 76  best acc: 0.8105\n",
      "epoch: 85  acc: 0.8102  best epoch: 76  best acc: 0.8105\n",
      "epoch: 86  acc: 0.8102  best epoch: 76  best acc: 0.8105\n",
      "epoch: 87  acc: 0.8101  best epoch: 76  best acc: 0.8105\n",
      "epoch: 88  acc: 0.8098  best epoch: 76  best acc: 0.8105\n",
      "epoch: 89  acc: 0.8102  best epoch: 76  best acc: 0.8105\n",
      "epoch: 90  acc: 0.8100  best epoch: 76  best acc: 0.8105\n",
      "epoch: 91  acc: 0.8102  best epoch: 76  best acc: 0.8105\n",
      "epoch: 92  acc: 0.8103  best epoch: 76  best acc: 0.8105\n",
      "epoch: 93  acc: 0.8100  best epoch: 76  best acc: 0.8105\n",
      "epoch: 94  acc: 0.8101  best epoch: 76  best acc: 0.8105\n",
      "epoch: 95  acc: 0.8100  best epoch: 76  best acc: 0.8105\n",
      "epoch: 96  acc: 0.8103  best epoch: 76  best acc: 0.8105\n",
      "epoch: 97  acc: 0.8099  best epoch: 76  best acc: 0.8105\n",
      "epoch: 98  acc: 0.8100  best epoch: 76  best acc: 0.8105\n",
      "epoch: 99  acc: 0.8097  best epoch: 76  best acc: 0.8105\n"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "conf_score = torch.tensor([0.8265, 0.8410, 0.7920, 0.7833, 0.7851, 0.8231, 0.8496, 0.8212, 0.8126,\n",
    "        0.8997])\n",
    "conf_score = conf_score.to(device)\n",
    "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
    "\n",
    "train_dataset = CIFAR10H(root='./data', train=False, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
    "print('train samples:',len(train_dataset), 'test samples:',len(test_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "model = models.resnet34(pretrained=True).to(device)\n",
    "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = CELossWithLS().to(device)\n",
    "\n",
    "best_epoch, best_acc = 0.0, 0\n",
    "for epoch in range(args.num_epoch):\n",
    "    if epoch is not 0 and epoch < 100 and epoch % 30 == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = param['lr'] / 10\n",
    "    train(model, train_loader, criterion, optimizer)\n",
    "    accuracy = test(model, test_loader)\n",
    "    if accuracy > best_acc:\n",
    "        patience = 0\n",
    "        best_acc = accuracy\n",
    "        best_epoch = epoch\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), 'best_model_cifar10h.pth_LS_lr.tar')\n",
    "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
    "            epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727aa44",
   "metadata": {},
   "source": [
    "CCA: get confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4416870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train samples: 10000 test samples: 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything()\n",
    "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
    "\n",
    "train_dataset = CIFAR10H(root='./data', train=False, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
    "print('train samples:',len(train_dataset), 'test samples:',len(test_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "model = models.resnet34(pretrained=True).to(device)\n",
    "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = CELossWithLS().to(device)\n",
    "model.load_state_dict(torch.load('best_model_cifar10h.pth_LS_lr.tar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684e3e6",
   "metadata": {},
   "source": [
    "Conf_score from Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42b3986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8525, 0.8496, 0.8505, 0.8509, 0.8511, 0.8459, 0.8480, 0.8501, 0.8526,\n",
       "        0.8531], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_cifar10h.pth_LS_lr.tar'))\n",
    "def get_conf_freq (model, dataloader):\n",
    "    model.eval()\n",
    "    conf_score = torch.zeros([10]).to(device)\n",
    "    count = torch.zeros([10]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, ad) in enumerate(dataloader):\n",
    "            inputs, targets, ad = inputs.to(device), targets.to(device), ad.to(device)\n",
    "            outputs = model(inputs)\n",
    "            softmaxes = F.softmax(outputs, dim=1)\n",
    "\n",
    "            for i in range (len(targets)):\n",
    "                confidence = softmaxes[i][targets[i]]\n",
    "                conf_score[targets[i]] += confidence\n",
    "                count[targets[i]] += 1\n",
    "            conf_avg = conf_score/count\n",
    "    return conf_avg\n",
    "\n",
    "conf_score = get_conf_freq(model, train_loader)\n",
    "conf_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3d859a",
   "metadata": {},
   "source": [
    "Conf_score from Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7304d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8188, 0.8767, 0.7144, 0.6143, 0.7532, 0.6945, 0.8224, 0.8255, 0.8705,\n",
       "        0.8474], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_cifar10h1.pth.tar'))\n",
    "def get_conf_freq (model, dataloader):\n",
    "    model.eval()\n",
    "    conf_score = torch.zeros([10]).to(device)\n",
    "    count = torch.zeros([10]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            softmaxes = F.softmax(outputs, dim=1)\n",
    "\n",
    "            for i in range (len(targets)):\n",
    "                confidence = softmaxes[i][targets[i]]\n",
    "                conf_score[targets[i]] += confidence\n",
    "                count[targets[i]] += 1\n",
    "            conf_avg = conf_score/count\n",
    "    return conf_avg\n",
    "\n",
    "conf_score_test = get_conf_freq(model, test_loader)\n",
    "conf_score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19ec590",
   "metadata": {},
   "source": [
    "ECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7fd3e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train samples: 10000 test samples: 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything()\n",
    "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
    "\n",
    "train_dataset = CIFAR10H(root='./data', train=False, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
    "print('train samples:',len(train_dataset), 'test samples:',len(test_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "model = models.resnet34(pretrained=True).to(device)\n",
    "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.load_state_dict(torch.load('best_model_cifar10h.pth_LS_lr.tar'))\n",
    "accuracy = test(model, test_loader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ea81d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81048"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = test(model, test_loader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced5cead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0673385038971901"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _ECELoss(nn.Module):\n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(_ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece\n",
    "    \n",
    "def evaluation(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    logits_list, labels_list = [], [] \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            logits_list.append(outputs)\n",
    "            labels_list.append(targets)\n",
    "            \n",
    "        logits_all = torch.cat(logits_list).cuda()\n",
    "        labels_all = torch.cat(labels_list).cuda()\n",
    "    return correct / total, logits_all, labels_all\n",
    "\n",
    "ece_criterion = _ECELoss().to(device)\n",
    "accuracy,logits_all,labels_all = evaluation(model, test_loader)\n",
    "logits_all = logits_all.view(-1,args.num_classes)\n",
    "labels_all = labels_all.view(-1)\n",
    "temperature_ece = ece_criterion(logits_all, labels_all).item()\n",
    "temperature_ece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59391bf6",
   "metadata": {},
   "source": [
    "Reliability Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6305720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def ece_eval(preds, targets, n_bins=15, bg_cls = -1):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    confidences, predictions = np.max(preds,1), np.argmax(preds,1)\n",
    "    confidences, predictions = confidences[targets>bg_cls], predictions[targets>bg_cls]\n",
    "    accuracies = (predictions == targets[targets>bg_cls]) \n",
    "    Bm, acc, conf = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
    "    ece = 0.0\n",
    "    bin_idx = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = np.logical_and(confidences > bin_lower, confidences <= bin_upper)\n",
    "        #in_bin = in_bin[targets>backgound_class]\n",
    "        bin_size = np.sum(in_bin)\n",
    "        \n",
    "        Bm[bin_idx] = bin_size\n",
    "        if bin_size > 0:  \n",
    "            accuracy_in_bin = np.sum(accuracies[in_bin])\n",
    "            acc[bin_idx] = accuracy_in_bin / Bm[bin_idx]\n",
    "            confidence_in_bin = np.sum(confidences[in_bin])\n",
    "            conf[bin_idx] = confidence_in_bin / Bm[bin_idx]\n",
    "        bin_idx += 1\n",
    "        \n",
    "    ece_all = Bm * np.abs((acc - conf))/ Bm.sum()\n",
    "    ece = ece_all.sum() \n",
    "    return ece, acc, conf, Bm\n",
    "\n",
    "\n",
    "def get_reliability_diagram(conf_avg, acc_avg, legend=None, leg_idx=0, n_bins=10, fig=2):\n",
    "    plt.figure(fig)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--',label = 'Perfect Calibration')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(0, 1.1, 1/n_bins))\n",
    "    plt.title('{}'.format(fig))\n",
    "    plt.plot(conf_avg[acc_avg>0],acc_avg[acc_avg>0], marker='.', label = legend)\n",
    "    plt.legend()\n",
    "    plt.savefig('ece_reliability_diag_{}.png'.format(fig),dpi=300)\n",
    "    \n",
    "logits_all =F.softmax(logits_all, dim=1).detach().cpu().numpy()\n",
    "labels_all =labels_all.detach().cpu().numpy()\n",
    "ece, acc, conf, Bm = ece_eval(logits_all, labels_all)\n",
    "get_reliability_diagram(conf, acc, legend='Reliability Diagram', fig='reliability_diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18368159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.18374131 0.2384659  0.30440519 0.37029691\n",
      " 0.43479381 0.49994309 0.56694725 0.63507871 0.70155298 0.77035246\n",
      " 0.84869463 0.87562958 0.96149758] <class 'numpy.ndarray'>\n",
      "[0.         0.         0.18181818 0.2519685  0.2798913  0.33419355\n",
      " 0.44942197 0.44324713 0.45650708 0.50434243 0.56532181 0.63724598\n",
      " 0.91055714 0.91053475 1.        ] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(conf, type(conf))\n",
    "print(acc,type(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94041a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
