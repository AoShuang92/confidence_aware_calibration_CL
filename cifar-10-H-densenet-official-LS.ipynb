{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8848f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  1 15:06:06 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P40           On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    50W / 250W |   4089MiB / 23040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P40           On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   22C    P8     8W / 250W |      2MiB / 23040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     30966      C   ...sa25729/myenv/bin/python3     4087MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93e3009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/cifar-10h\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/jcpeterson/cifar-10h\n",
    "%cd cifar-10h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409ba526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import argparse\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "def seed_everything(seed=12):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "parser = argparse.ArgumentParser(description='CIFAR-10H Training')\n",
    "parser.add_argument('--lr', default=5e-2, type=float, help='learning rate')\n",
    "parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
    "parser.add_argument('--batch_size', default=1024, type=int, help='batch size')\n",
    "parser.add_argument('--test_batch_size', default=2048, type=int, help='batch size')\n",
    "parser.add_argument('--num_epoch', default=100, type=int, help='epoch number')\n",
    "parser.add_argument('--num_classes', type=int, default=10, help='number classes')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585d2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets, ad) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b4048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "class CIFAR10H(torchvision.datasets.CIFAR10):\n",
    "\n",
    "    def __init__(self, root,  rand_number=0, train=False, transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        super(CIFAR10H, self).__init__(root, train, transform, target_transform, download) \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.ad = np.load(os.path.join(root,'cifar10h-probs.npy'))\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "        ad = self.ad[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target, ad\n",
    "\n",
    "class CELossWithLS(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, classes= args.num_classes, smoothing=0.1, ignore_index=-1):\n",
    "        super(CELossWithLS, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.complement = 1.0 - smoothing\n",
    "        self.cls = classes\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        with torch.no_grad():\n",
    "#             new_smoothing  = self.smoothing - conf_score/10\n",
    "#             new_complement = 1 - new_smoothing\n",
    "            oh_labels = F.one_hot(target.to(torch.int64), num_classes = self.cls).contiguous()\n",
    "            smoothen_ohlabel = oh_labels * self.complement + self.smoothing / self.cls\n",
    "        \n",
    "        logs = self.log_softmax(logits[target!=self.ignore_index])\n",
    "        return -torch.sum(logs * smoothen_ohlabel[target!=self.ignore_index], dim=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce9466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train samples: 10000 test samples: 50000\n",
      "epoch: 0  acc: 0.4243  best epoch: 0  best acc: 0.4243\n",
      "epoch: 1  acc: 0.5053  best epoch: 1  best acc: 0.5053\n",
      "epoch: 2  acc: 0.6119  best epoch: 2  best acc: 0.6119\n",
      "epoch: 3  acc: 0.6917  best epoch: 3  best acc: 0.6917\n",
      "epoch: 4  acc: 0.7142  best epoch: 4  best acc: 0.7142\n",
      "epoch: 5  acc: 0.7634  best epoch: 5  best acc: 0.7634\n",
      "epoch: 6  acc: 0.7721  best epoch: 6  best acc: 0.7721\n",
      "epoch: 7  acc: 0.7836  best epoch: 7  best acc: 0.7836\n",
      "epoch: 8  acc: 0.7879  best epoch: 8  best acc: 0.7879\n",
      "epoch: 9  acc: 0.7714  best epoch: 8  best acc: 0.7879\n",
      "epoch: 10  acc: 0.7828  best epoch: 8  best acc: 0.7879\n",
      "epoch: 11  acc: 0.7859  best epoch: 8  best acc: 0.7879\n",
      "epoch: 12  acc: 0.7781  best epoch: 8  best acc: 0.7879\n",
      "epoch: 13  acc: 0.7938  best epoch: 13  best acc: 0.7938\n",
      "epoch: 14  acc: 0.7925  best epoch: 13  best acc: 0.7938\n",
      "epoch: 15  acc: 0.7936  best epoch: 13  best acc: 0.7938\n",
      "epoch: 16  acc: 0.8023  best epoch: 16  best acc: 0.8023\n",
      "epoch: 17  acc: 0.8059  best epoch: 17  best acc: 0.8059\n",
      "epoch: 18  acc: 0.8077  best epoch: 18  best acc: 0.8077\n",
      "epoch: 19  acc: 0.8086  best epoch: 19  best acc: 0.8086\n",
      "epoch: 20  acc: 0.8053  best epoch: 19  best acc: 0.8086\n",
      "epoch: 21  acc: 0.8082  best epoch: 19  best acc: 0.8086\n",
      "epoch: 22  acc: 0.8064  best epoch: 19  best acc: 0.8086\n",
      "epoch: 23  acc: 0.8082  best epoch: 19  best acc: 0.8086\n",
      "epoch: 24  acc: 0.8120  best epoch: 24  best acc: 0.8120\n",
      "epoch: 25  acc: 0.8109  best epoch: 24  best acc: 0.8120\n",
      "epoch: 26  acc: 0.8105  best epoch: 24  best acc: 0.8120\n",
      "epoch: 27  acc: 0.8126  best epoch: 27  best acc: 0.8126\n",
      "epoch: 28  acc: 0.8098  best epoch: 27  best acc: 0.8126\n",
      "epoch: 29  acc: 0.8115  best epoch: 27  best acc: 0.8126\n",
      "epoch: 30  acc: 0.8165  best epoch: 30  best acc: 0.8165\n",
      "epoch: 31  acc: 0.8182  best epoch: 31  best acc: 0.8182\n",
      "epoch: 32  acc: 0.8192  best epoch: 32  best acc: 0.8192\n",
      "epoch: 33  acc: 0.8190  best epoch: 32  best acc: 0.8192\n",
      "epoch: 34  acc: 0.8199  best epoch: 34  best acc: 0.8199\n",
      "epoch: 35  acc: 0.8202  best epoch: 35  best acc: 0.8202\n",
      "epoch: 36  acc: 0.8208  best epoch: 36  best acc: 0.8208\n",
      "epoch: 37  acc: 0.8209  best epoch: 37  best acc: 0.8209\n",
      "epoch: 38  acc: 0.8211  best epoch: 38  best acc: 0.8211\n",
      "epoch: 39  acc: 0.8211  best epoch: 39  best acc: 0.8211\n",
      "epoch: 40  acc: 0.8218  best epoch: 40  best acc: 0.8218\n",
      "epoch: 41  acc: 0.8223  best epoch: 41  best acc: 0.8223\n",
      "epoch: 42  acc: 0.8225  best epoch: 42  best acc: 0.8225\n",
      "epoch: 43  acc: 0.8228  best epoch: 43  best acc: 0.8228\n",
      "epoch: 44  acc: 0.8232  best epoch: 44  best acc: 0.8232\n",
      "epoch: 45  acc: 0.8233  best epoch: 45  best acc: 0.8233\n",
      "epoch: 46  acc: 0.8228  best epoch: 45  best acc: 0.8233\n",
      "epoch: 47  acc: 0.8230  best epoch: 45  best acc: 0.8233\n",
      "epoch: 48  acc: 0.8236  best epoch: 48  best acc: 0.8236\n",
      "epoch: 49  acc: 0.8243  best epoch: 49  best acc: 0.8243\n",
      "epoch: 50  acc: 0.8242  best epoch: 49  best acc: 0.8243\n",
      "epoch: 51  acc: 0.8237  best epoch: 49  best acc: 0.8243\n",
      "epoch: 52  acc: 0.8236  best epoch: 49  best acc: 0.8243\n",
      "epoch: 53  acc: 0.8232  best epoch: 49  best acc: 0.8243\n",
      "epoch: 54  acc: 0.8235  best epoch: 49  best acc: 0.8243\n",
      "epoch: 55  acc: 0.8240  best epoch: 49  best acc: 0.8243\n",
      "epoch: 56  acc: 0.8241  best epoch: 49  best acc: 0.8243\n",
      "epoch: 57  acc: 0.8244  best epoch: 57  best acc: 0.8244\n",
      "epoch: 58  acc: 0.8248  best epoch: 58  best acc: 0.8248\n",
      "epoch: 59  acc: 0.8248  best epoch: 59  best acc: 0.8248\n",
      "epoch: 60  acc: 0.8247  best epoch: 59  best acc: 0.8248\n",
      "epoch: 61  acc: 0.8249  best epoch: 61  best acc: 0.8249\n",
      "epoch: 62  acc: 0.8247  best epoch: 61  best acc: 0.8249\n",
      "epoch: 63  acc: 0.8249  best epoch: 63  best acc: 0.8249\n",
      "epoch: 64  acc: 0.8248  best epoch: 63  best acc: 0.8249\n",
      "epoch: 65  acc: 0.8250  best epoch: 65  best acc: 0.8250\n",
      "epoch: 66  acc: 0.8251  best epoch: 66  best acc: 0.8251\n",
      "epoch: 67  acc: 0.8253  best epoch: 67  best acc: 0.8253\n",
      "epoch: 68  acc: 0.8247  best epoch: 67  best acc: 0.8253\n",
      "epoch: 69  acc: 0.8244  best epoch: 67  best acc: 0.8253\n",
      "epoch: 70  acc: 0.8249  best epoch: 67  best acc: 0.8253\n",
      "epoch: 71  acc: 0.8249  best epoch: 67  best acc: 0.8253\n",
      "epoch: 72  acc: 0.8252  best epoch: 67  best acc: 0.8253\n",
      "epoch: 73  acc: 0.8249  best epoch: 67  best acc: 0.8253\n",
      "epoch: 74  acc: 0.8247  best epoch: 67  best acc: 0.8253\n",
      "epoch: 75  acc: 0.8250  best epoch: 67  best acc: 0.8253\n",
      "epoch: 76  acc: 0.8248  best epoch: 67  best acc: 0.8253\n",
      "epoch: 77  acc: 0.8248  best epoch: 67  best acc: 0.8253\n",
      "epoch: 78  acc: 0.8247  best epoch: 67  best acc: 0.8253\n",
      "epoch: 79  acc: 0.8249  best epoch: 67  best acc: 0.8253\n",
      "epoch: 80  acc: 0.8249  best epoch: 67  best acc: 0.8253\n",
      "epoch: 81  acc: 0.8251  best epoch: 67  best acc: 0.8253\n",
      "epoch: 82  acc: 0.8251  best epoch: 67  best acc: 0.8253\n",
      "epoch: 83  acc: 0.8247  best epoch: 67  best acc: 0.8253\n",
      "epoch: 84  acc: 0.8245  best epoch: 67  best acc: 0.8253\n",
      "epoch: 85  acc: 0.8248  best epoch: 67  best acc: 0.8253\n",
      "epoch: 86  acc: 0.8246  best epoch: 67  best acc: 0.8253\n",
      "epoch: 87  acc: 0.8250  best epoch: 67  best acc: 0.8253\n",
      "epoch: 88  acc: 0.8247  best epoch: 67  best acc: 0.8253\n",
      "epoch: 89  acc: 0.8247  best epoch: 67  best acc: 0.8253\n",
      "epoch: 90  acc: 0.8245  best epoch: 67  best acc: 0.8253\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ded601565931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f54ec337534a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "conf_score = torch.tensor([0.8265, 0.8410, 0.7920, 0.7833, 0.7851, 0.8231, 0.8496, 0.8212, 0.8126,\n",
    "        0.8997])\n",
    "conf_score = conf_score.to(device)\n",
    "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
    "\n",
    "train_dataset = CIFAR10H(root='./data', train=False, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
    "print('train samples:',len(train_dataset), 'test samples:',len(test_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# model = models.resnet34(pretrained=True).to(device)\n",
    "# model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
    "model = models.densenet121(pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, args.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = CELossWithLS().to(device)\n",
    "\n",
    "best_epoch, best_acc = 0.0, 0\n",
    "for epoch in range(args.num_epoch):\n",
    "    if epoch is not 0 and epoch < 100 and epoch % 30 == 0:\n",
    "        for param in optimizer.param_groups:\n",
    "            param['lr'] = param['lr'] / 10\n",
    "    train(model, train_loader, criterion, optimizer)\n",
    "    accuracy = test(model, test_loader)\n",
    "    if accuracy > best_acc:\n",
    "        patience = 0\n",
    "        best_acc = accuracy\n",
    "        best_epoch = epoch\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), 'best_model_densenet_cifar10h_LS.pth.tar')\n",
    "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
    "            epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727aa44",
   "metadata": {},
   "source": [
    "CCA: get confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4416870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train samples: 10000 test samples: 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything()\n",
    "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
    "\n",
    "train_dataset = CIFAR10H(root='./data', train=False, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
    "print('train samples:',len(train_dataset), 'test samples:',len(test_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "model = models.densenet121(pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, args.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = CELossWithLS().to(device)\n",
    "model.load_state_dict(torch.load('best_model_densenet_cifar10h_LS.pth.tar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684e3e6",
   "metadata": {},
   "source": [
    "Conf_score from Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42b3986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8777, 0.8785, 0.8794, 0.8755, 0.8767, 0.8753, 0.8796, 0.8776, 0.8787,\n",
       "        0.8761], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_densenet_cifar10h_LS.pth.tar'))\n",
    "def get_conf_freq (model, dataloader):\n",
    "    model.eval()\n",
    "    conf_score = torch.zeros([10]).to(device)\n",
    "    count = torch.zeros([10]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, ad) in enumerate(dataloader):\n",
    "            inputs, targets, ad = inputs.to(device), targets.to(device), ad.to(device)\n",
    "            outputs = model(inputs)\n",
    "            softmaxes = F.softmax(outputs, dim=1)\n",
    "\n",
    "            for i in range (len(targets)):\n",
    "                confidence = softmaxes[i][targets[i]]\n",
    "                conf_score[targets[i]] += confidence\n",
    "                count[targets[i]] += 1\n",
    "            conf_avg = conf_score/count\n",
    "    return conf_avg\n",
    "\n",
    "conf_score = get_conf_freq(model, train_loader)\n",
    "conf_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3d859a",
   "metadata": {},
   "source": [
    "Conf_score from Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7304d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7302, 0.7770, 0.6318, 0.5577, 0.6675, 0.5952, 0.7345, 0.7209, 0.7781,\n",
       "        0.7606], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_densenet_cifar10h_LS.pth.tar'))\n",
    "def get_conf_freq (model, dataloader):\n",
    "    model.eval()\n",
    "    conf_score = torch.zeros([10]).to(device)\n",
    "    count = torch.zeros([10]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            softmaxes = F.softmax(outputs, dim=1)\n",
    "\n",
    "            for i in range (len(targets)):\n",
    "                confidence = softmaxes[i][targets[i]]\n",
    "                conf_score[targets[i]] += confidence\n",
    "                count[targets[i]] += 1\n",
    "            conf_avg = conf_score/count\n",
    "    return conf_avg\n",
    "\n",
    "conf_score_test = get_conf_freq(model, test_loader)\n",
    "conf_score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19ec590",
   "metadata": {},
   "source": [
    "ECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fd3e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train samples: 10000 test samples: 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76732"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything()\n",
    "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
    "\n",
    "train_dataset = CIFAR10H(root='./data', train=False, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
    "print('train samples:',len(train_dataset), 'test samples:',len(test_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "model = models.densenet121(pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, args.num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.load_state_dict(torch.load('best_model_densenet_cifar10h_LS.pth.tar'))\n",
    "accuracy = test(model, test_loader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced5cead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05411430075764656"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _ECELoss(nn.Module):\n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(_ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece\n",
    "    \n",
    "def evaluation(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    logits_list, labels_list = [], [] \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            logits_list.append(outputs)\n",
    "            labels_list.append(targets)\n",
    "            \n",
    "        logits_all = torch.cat(logits_list).cuda()\n",
    "        labels_all = torch.cat(labels_list).cuda()\n",
    "    return correct / total, logits_all, labels_all\n",
    "\n",
    "ece_criterion = _ECELoss().to(device)\n",
    "accuracy,logits_all,labels_all = evaluation(model, test_loader)\n",
    "logits_all = logits_all.view(-1,args.num_classes)\n",
    "labels_all = labels_all.view(-1)\n",
    "temperature_ece = ece_criterion(logits_all, labels_all).item()\n",
    "temperature_ece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59391bf6",
   "metadata": {},
   "source": [
    "Reliability Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6305720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def ece_eval(preds, targets, n_bins=15, bg_cls = -1):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    confidences, predictions = np.max(preds,1), np.argmax(preds,1)\n",
    "    confidences, predictions = confidences[targets>bg_cls], predictions[targets>bg_cls]\n",
    "    accuracies = (predictions == targets[targets>bg_cls]) \n",
    "    Bm, acc, conf = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
    "    ece = 0.0\n",
    "    bin_idx = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = np.logical_and(confidences > bin_lower, confidences <= bin_upper)\n",
    "        #in_bin = in_bin[targets>backgound_class]\n",
    "        bin_size = np.sum(in_bin)\n",
    "        \n",
    "        Bm[bin_idx] = bin_size\n",
    "        if bin_size > 0:  \n",
    "            accuracy_in_bin = np.sum(accuracies[in_bin])\n",
    "            acc[bin_idx] = accuracy_in_bin / Bm[bin_idx]\n",
    "            confidence_in_bin = np.sum(confidences[in_bin])\n",
    "            conf[bin_idx] = confidence_in_bin / Bm[bin_idx]\n",
    "        bin_idx += 1\n",
    "        \n",
    "    ece_all = Bm * np.abs((acc - conf))/ Bm.sum()\n",
    "    ece = ece_all.sum() \n",
    "    return ece, acc, conf, Bm\n",
    "\n",
    "\n",
    "def get_reliability_diagram(conf_avg, acc_avg, legend=None, leg_idx=0, n_bins=10, fig=2):\n",
    "    plt.figure(fig)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--',label = 'Perfect Calibration')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(0, 1.1, 1/n_bins))\n",
    "    plt.title('{}'.format(fig))\n",
    "    plt.plot(conf_avg[acc_avg>0],acc_avg[acc_avg>0], marker='.', label = legend)\n",
    "    plt.legend()\n",
    "    plt.savefig('ece_reliability_diag_{}.png'.format(fig),dpi=300)\n",
    "    \n",
    "logits_all =F.softmax(logits_all, dim=1).detach().cpu().numpy()\n",
    "labels_all =labels_all.detach().cpu().numpy()\n",
    "ece, acc, conf, Bm = ece_eval(logits_all, labels_all)\n",
    "get_reliability_diagram(conf, acc, legend='Reliability Diagram', fig='reliability_diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18368159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.17671801 0.24058014 0.30230227 0.36858973\n",
      " 0.43423661 0.49944409 0.56609515 0.63506396 0.70124221 0.76970547\n",
      " 0.84300492 0.89008204 0.94509403] <class 'numpy.ndarray'>\n",
      "[0.         0.         0.34782609 0.28611898 0.33655006 0.40912548\n",
      " 0.47138047 0.49266703 0.54034896 0.61176471 0.6647351  0.75424436\n",
      " 0.89553863 0.96509629 0.92352941] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(conf, type(conf))\n",
    "print(acc,type(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94041a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
