{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ef929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 30 12:39:56 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P40           On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    51W / 250W |   4696MiB / 23040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P40           On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   45C    P8    10W / 250W |      2MiB / 23040MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     25713      C   ...sa25729/myenv/bin/python3     2347MiB |\n",
      "|    0   N/A  N/A     29424      C   ...sa25729/myenv/bin/python3     2347MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85afaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f86cabb1af8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "import os\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def seed_everything(seed=12):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "RANDOM_SEED = 12\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95d6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed_wikiart_title.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786e6536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Token count')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "token_lens = []\n",
    "\n",
    "for txt in df.Title:\n",
    "    tokens = tokenizer.encode(txt, max_length=30)\n",
    "    token_lens.append(len(tokens))\n",
    "\n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 30]);\n",
    "plt.xlabel('Token count')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8f3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 30\n",
    "class Wikiart_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, title, targets, tokenizer, max_len):\n",
    "        self.title = title\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.title[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          review,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=True,\n",
    "          pad_to_max_length=True,\n",
    "          return_attention_mask=True,\n",
    "          \n",
    "          return_tensors='pt',\n",
    "        )\n",
    "        ids = encoding['input_ids']\n",
    "        mask = encoding['attention_mask']\n",
    "       \n",
    "        \n",
    "        return {\n",
    "          \n",
    "          'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "           'mask': torch.tensor(mask, dtype=torch.long),\n",
    "           'targets': torch.tensor(self.targets[item], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a3a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e91254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/user-data/sa25729/myenv/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'mask', 'targets'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = Wikiart_Dataset(\n",
    "    title=df.Title.to_numpy(),\n",
    "    targets=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "    return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2\n",
    "  )\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "data = next(iter(train_data_loader))\n",
    "data.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6689b2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "n_classes=6\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=n_classes).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c1e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 6\n",
    "class CE_LS(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, classes= num_classes, smoothing=0.13, ignore_index=-1):\n",
    "        super(CE_LS, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.complement = 1.0 - smoothing\n",
    "        self.cls = classes\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            oh_labels = F.one_hot(target.to(torch.int64), num_classes = self.cls).contiguous()\n",
    "            smoothen_ohlabel = oh_labels * self.complement + self.smoothing / self.cls\n",
    "        \n",
    "        logs = self.log_softmax(logits[target!=self.ignore_index])\n",
    "        return -torch.sum(logs * smoothen_ohlabel[target!=self.ignore_index], dim=1).mean()\n",
    "    \n",
    "\n",
    "loss_fn = CE_LS(classes = num_classes).to(device)\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask = d[\"mask\"].squeeze(1).to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        ).logits\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets.long())\n",
    "\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask = d[\"mask\"].squeeze(1).to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                ).logits\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets.long())\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60efb462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Train loss 1.2412629295321345 accuracy 0.6141900121802679\n",
      "Val loss 1.1628423310243166 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 0  acc: 0.6687  best epoch: 0  best acc: 0.6687 lr: 0.0000\n",
      "Epoch 2/100\n",
      "----------\n",
      "Train loss 0.9862299891351496 accuracy 0.7658343483556638\n",
      "Val loss 1.2000217254345233 accuracy 0.6504263093788063\n",
      "\n",
      "epoch: 1  acc: 0.6504  best epoch: 0  best acc: 0.6687 lr: 0.0000\n",
      "Epoch 3/100\n",
      "----------\n",
      "Train loss 0.8334041995909608 accuracy 0.8453105968331303\n",
      "Val loss 1.2183376390200396 accuracy 0.684531059683313\n",
      "\n",
      "epoch: 2  acc: 0.6845  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 4/100\n",
      "----------\n",
      "Train loss 0.7351726895397149 accuracy 0.8943361753958586\n",
      "Val loss 1.294175216784844 accuracy 0.6772228989037758\n",
      "\n",
      "epoch: 3  acc: 0.6772  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 5/100\n",
      "----------\n",
      "Train loss 0.6763339881758088 accuracy 0.921741778319123\n",
      "Val loss 1.3529510681445782 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 4  acc: 0.6626  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 6/100\n",
      "----------\n",
      "Train loss 0.6371573881038184 accuracy 0.9427527405602922\n",
      "Val loss 1.3471314288102663 accuracy 0.6796589524969548\n",
      "\n",
      "epoch: 5  acc: 0.6797  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 7/100\n",
      "----------\n",
      "Train loss 0.6100475076332833 accuracy 0.9549330085261876\n",
      "Val loss 1.3938941267820506 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 6  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 8/100\n",
      "----------\n",
      "Train loss 0.5937942428496278 accuracy 0.9643727161997564\n",
      "Val loss 1.4029048818808336 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 7  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 9/100\n",
      "----------\n",
      "Train loss 0.5821724134741477 accuracy 0.9701583434835566\n",
      "Val loss 1.3975407710442176 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 8  acc: 0.6699  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 10/100\n",
      "----------\n",
      "Train loss 0.57335266557712 accuracy 0.9744214372716199\n",
      "Val loss 1.4441407735531147 accuracy 0.658952496954933\n",
      "\n",
      "epoch: 9  acc: 0.6590  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 11/100\n",
      "----------\n",
      "Train loss 0.5682744175485037 accuracy 0.9750304506699147\n",
      "Val loss 1.434328711949862 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 10  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 12/100\n",
      "----------\n",
      "Train loss 0.5700121446720605 accuracy 0.9756394640682094\n",
      "Val loss 1.4276491907926707 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 11  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 13/100\n",
      "----------\n",
      "Train loss 0.5660368788589552 accuracy 0.9765529841656516\n",
      "Val loss 1.4369978950573847 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 12  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 14/100\n",
      "----------\n",
      "Train loss 0.5621955064893926 accuracy 0.976857490864799\n",
      "Val loss 1.4300745312984173 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 13  acc: 0.6687  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 15/100\n",
      "----------\n",
      "Train loss 0.5625901146999841 accuracy 0.9780755176613884\n",
      "Val loss 1.432394761305589 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 14  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 16/100\n",
      "----------\n",
      "Train loss 0.5606506003916842 accuracy 0.976857490864799\n",
      "Val loss 1.4460174991534307 accuracy 0.6650426309378806\n",
      "\n",
      "epoch: 15  acc: 0.6650  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 17/100\n",
      "----------\n",
      "Train loss 0.5597588072702723 accuracy 0.9777710109622411\n",
      "Val loss 1.4452897768754225 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 16  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 18/100\n",
      "----------\n",
      "Train loss 0.558859749905114 accuracy 0.9774665042630938\n",
      "Val loss 1.435946496633383 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 17  acc: 0.6675  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 19/100\n",
      "----------\n",
      "Train loss 0.5577925432075574 accuracy 0.9765529841656516\n",
      "Val loss 1.43455905180711 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 18  acc: 0.6675  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 20/100\n",
      "----------\n",
      "Train loss 0.5555587173665612 accuracy 0.9789890377588306\n",
      "Val loss 1.4526425691751332 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 19  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 21/100\n",
      "----------\n",
      "Train loss 0.5578231412230186 accuracy 0.9756394640682094\n",
      "Val loss 1.4438487107937152 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 20  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 22/100\n",
      "----------\n",
      "Train loss 0.5559738920730295 accuracy 0.9786845310596832\n",
      "Val loss 1.442340681186089 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 21  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 23/100\n",
      "----------\n",
      "Train loss 0.5557155811670914 accuracy 0.9756394640682094\n",
      "Val loss 1.4406615220583403 accuracy 0.6833130328867235\n",
      "\n",
      "epoch: 22  acc: 0.6833  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 24/100\n",
      "----------\n",
      "Train loss 0.5561604019507621 accuracy 0.9771619975639464\n",
      "Val loss 1.4397960626162016 accuracy 0.6808769792935444\n",
      "\n",
      "epoch: 23  acc: 0.6809  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 25/100\n",
      "----------\n",
      "Train loss 0.5552207879649783 accuracy 0.9771619975639464\n",
      "Val loss 1.451716810464859 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 24  acc: 0.6711  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 26/100\n",
      "----------\n",
      "Train loss 0.5552243312585701 accuracy 0.9759439707673568\n",
      "Val loss 1.4437249761361342 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 25  acc: 0.6760  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 27/100\n",
      "----------\n",
      "Train loss 0.5546020280967638 accuracy 0.976857490864799\n",
      "Val loss 1.461598052428319 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 26  acc: 0.6699  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 28/100\n",
      "----------\n",
      "Train loss 0.5549897487881115 accuracy 0.9765529841656516\n",
      "Val loss 1.4548742771148682 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 27  acc: 0.6724  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 29/100\n",
      "----------\n",
      "Train loss 0.5536219217244861 accuracy 0.9789890377588306\n",
      "Val loss 1.4541908961076002 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 28  acc: 0.6699  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 30/100\n",
      "----------\n",
      "Train loss 0.5534509021101646 accuracy 0.9780755176613884\n",
      "Val loss 1.4486992061138153 accuracy 0.6747868453105969\n",
      "\n",
      "epoch: 29  acc: 0.6748  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 31/100\n",
      "----------\n",
      "Train loss 0.5540635267507683 accuracy 0.9765529841656516\n",
      "Val loss 1.4647930608345912 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 30  acc: 0.6736  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 32/100\n",
      "----------\n",
      "Train loss 0.5538736570228651 accuracy 0.9777710109622411\n",
      "Val loss 1.4646693101296058 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 31  acc: 0.6675  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 33/100\n",
      "----------\n",
      "Train loss 0.5532409733938939 accuracy 0.9780755176613884\n",
      "Val loss 1.4646769097218146 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 32  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 34/100\n",
      "----------\n",
      "Train loss 0.5532845229778475 accuracy 0.9774665042630938\n",
      "Val loss 1.4693547831131861 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 33  acc: 0.6663  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 35/100\n",
      "----------\n",
      "Train loss 0.5557254147761076 accuracy 0.9774665042630938\n",
      "Val loss 1.479534048300523 accuracy 0.6601705237515225\n",
      "\n",
      "epoch: 34  acc: 0.6602  best epoch: 2  best acc: 0.6845 lr: 0.0000\n",
      "Epoch 36/100\n",
      "----------\n",
      "Train loss 0.5538676872994136 accuracy 0.9783800243605358\n",
      "Val loss 1.4381400874027839 accuracy 0.6869671132764921\n",
      "\n",
      "epoch: 35  acc: 0.6870  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 37/100\n",
      "----------\n",
      "Train loss 0.5527836211676737 accuracy 0.9774665042630938\n",
      "Val loss 1.4533139283840473 accuracy 0.6760048721071863\n",
      "\n",
      "epoch: 36  acc: 0.6760  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 38/100\n",
      "----------\n",
      "Train loss 0.5524776115000827 accuracy 0.9780755176613884\n",
      "Val loss 1.4542360237011542 accuracy 0.6784409257003654\n",
      "\n",
      "epoch: 37  acc: 0.6784  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 39/100\n",
      "----------\n",
      "Train loss 0.5529632932931474 accuracy 0.9786845310596832\n",
      "Val loss 1.4723262695165782 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 38  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 40/100\n",
      "----------\n",
      "Train loss 0.5521259082173838 accuracy 0.979293544457978\n",
      "Val loss 1.4679209406559284 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 39  acc: 0.6724  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 41/100\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5524445332369758 accuracy 0.979293544457978\n",
      "Val loss 1.469611461345966 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 40  acc: 0.6663  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 42/100\n",
      "----------\n",
      "Train loss 0.5521248145010865 accuracy 0.9783800243605358\n",
      "Val loss 1.4654261011343737 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 41  acc: 0.6724  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 43/100\n",
      "----------\n",
      "Train loss 0.5525770476720866 accuracy 0.9777710109622411\n",
      "Val loss 1.4748283808047955 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 42  acc: 0.6699  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 44/100\n",
      "----------\n",
      "Train loss 0.5519622552742078 accuracy 0.9795980511571254\n",
      "Val loss 1.4735659544284527 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 43  acc: 0.6675  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 45/100\n",
      "----------\n",
      "Train loss 0.5521968174906611 accuracy 0.9789890377588306\n",
      "Val loss 1.4703751160548284 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 44  acc: 0.6736  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 46/100\n",
      "----------\n",
      "Train loss 0.5520117919421891 accuracy 0.979293544457978\n",
      "Val loss 1.4715790977844825 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 45  acc: 0.6711  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 47/100\n",
      "----------\n",
      "Train loss 0.5521070216465922 accuracy 0.9783800243605358\n",
      "Val loss 1.4732221548373883 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 46  acc: 0.6724  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 48/100\n",
      "----------\n",
      "Train loss 0.5513538556191527 accuracy 0.9795980511571254\n",
      "Val loss 1.4721157504962041 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 47  acc: 0.6736  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 49/100\n",
      "----------\n",
      "Train loss 0.5525695554261069 accuracy 0.9799025578562728\n",
      "Val loss 1.4732213616371155 accuracy 0.6735688185140073\n",
      "\n",
      "epoch: 48  acc: 0.6736  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 50/100\n",
      "----------\n",
      "Train loss 0.5513214347431961 accuracy 0.9786845310596832\n",
      "Val loss 1.4769385273639972 accuracy 0.6650426309378806\n",
      "\n",
      "epoch: 49  acc: 0.6650  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 51/100\n",
      "----------\n",
      "Train loss 0.551558161244809 accuracy 0.979293544457978\n",
      "Val loss 1.4589064717292786 accuracy 0.6747868453105969\n",
      "\n",
      "epoch: 50  acc: 0.6748  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 52/100\n",
      "----------\n",
      "Train loss 0.5511387048415768 accuracy 0.9799025578562728\n",
      "Val loss 1.4722629647988539 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 51  acc: 0.6724  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 53/100\n",
      "----------\n",
      "Train loss 0.5510554880771822 accuracy 0.9786845310596832\n",
      "Val loss 1.4823371401199927 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 52  acc: 0.6663  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 54/100\n",
      "----------\n",
      "Train loss 0.5526557275392476 accuracy 0.979293544457978\n",
      "Val loss 1.4618119093088002 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 53  acc: 0.6699  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 55/100\n",
      "----------\n",
      "Train loss 0.5514553686947499 accuracy 0.9783800243605358\n",
      "Val loss 1.465977627497453 accuracy 0.6723507917174177\n",
      "\n",
      "epoch: 54  acc: 0.6724  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 56/100\n",
      "----------\n",
      "Train loss 0.5513729186891352 accuracy 0.9799025578562728\n",
      "Val loss 1.46101464675023 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 55  acc: 0.6711  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 57/100\n",
      "----------\n",
      "Train loss 0.5520398946641718 accuracy 0.9777710109622411\n",
      "Val loss 1.480882887656872 accuracy 0.6601705237515225\n",
      "\n",
      "epoch: 56  acc: 0.6602  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 58/100\n",
      "----------\n",
      "Train loss 0.5512752006354841 accuracy 0.9786845310596832\n",
      "Val loss 1.4692890414824853 accuracy 0.6686967113276492\n",
      "\n",
      "epoch: 57  acc: 0.6687  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 59/100\n",
      "----------\n",
      "Train loss 0.5515657854311674 accuracy 0.9789890377588306\n",
      "Val loss 1.4807655352812548 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 58  acc: 0.6699  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 60/100\n",
      "----------\n",
      "Train loss 0.5522616910702974 accuracy 0.9786845310596832\n",
      "Val loss 1.4610156462742732 accuracy 0.6772228989037758\n",
      "\n",
      "epoch: 59  acc: 0.6772  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 61/100\n",
      "----------\n",
      "Train loss 0.5520445339888045 accuracy 0.979293544457978\n",
      "Val loss 1.4870404669871697 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 60  acc: 0.6699  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 62/100\n",
      "----------\n",
      "Train loss 0.5514997417486988 accuracy 0.9786845310596832\n",
      "Val loss 1.4990085638486421 accuracy 0.658952496954933\n",
      "\n",
      "epoch: 61  acc: 0.6590  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 63/100\n",
      "----------\n",
      "Train loss 0.5507905321213805 accuracy 0.9799025578562728\n",
      "Val loss 1.4976962117048411 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 62  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 64/100\n",
      "----------\n",
      "Train loss 0.5517011718842589 accuracy 0.9799025578562728\n",
      "Val loss 1.463881648503817 accuracy 0.6699147381242387\n",
      "\n",
      "epoch: 63  acc: 0.6699  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 65/100\n",
      "----------\n",
      "Train loss 0.5524027173958935 accuracy 0.9777710109622411\n",
      "Val loss 1.489192022727086 accuracy 0.6577344701583434\n",
      "\n",
      "epoch: 64  acc: 0.6577  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 66/100\n",
      "----------\n",
      "Train loss 0.5516484877438221 accuracy 0.9802070645554202\n",
      "Val loss 1.4946745313130891 accuracy 0.656516443361754\n",
      "\n",
      "epoch: 65  acc: 0.6565  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 67/100\n",
      "----------\n",
      "Train loss 0.5512545652759885 accuracy 0.9789890377588306\n",
      "Val loss 1.4878251690130968 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 66  acc: 0.6663  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 68/100\n",
      "----------\n",
      "Train loss 0.5509540403930886 accuracy 0.9789890377588306\n",
      "Val loss 1.4952664146056542 accuracy 0.656516443361754\n",
      "\n",
      "epoch: 67  acc: 0.6565  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 69/100\n",
      "----------\n",
      "Train loss 0.5511301281382737 accuracy 0.9789890377588306\n",
      "Val loss 1.4943637526952303 accuracy 0.658952496954933\n",
      "\n",
      "epoch: 68  acc: 0.6590  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 70/100\n",
      "----------\n",
      "Train loss 0.5510285936512993 accuracy 0.979293544457978\n",
      "Val loss 1.4896636788661664 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 69  acc: 0.6663  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 71/100\n",
      "----------\n",
      "Train loss 0.5509060256689498 accuracy 0.9795980511571254\n",
      "Val loss 1.4894310465225806 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 70  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 72/100\n",
      "----------\n",
      "Train loss 0.550567843381641 accuracy 0.9789890377588306\n",
      "Val loss 1.4863470425972571 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 71  acc: 0.6663  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 73/100\n",
      "----------\n",
      "Train loss 0.5508256085868021 accuracy 0.9805115712545676\n",
      "Val loss 1.4963154792785645 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 72  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 74/100\n",
      "----------\n",
      "Train loss 0.5506312748760853 accuracy 0.9795980511571254\n",
      "Val loss 1.5010486795352056 accuracy 0.656516443361754\n",
      "\n",
      "epoch: 73  acc: 0.6565  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 75/100\n",
      "----------\n",
      "Train loss 0.5516729921970552 accuracy 0.9802070645554202\n",
      "Val loss 1.5005049476256738 accuracy 0.6577344701583434\n",
      "\n",
      "epoch: 74  acc: 0.6577  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 76/100\n",
      "----------\n",
      "Train loss 0.5504939938054502 accuracy 0.9805115712545676\n",
      "Val loss 1.5026730069747338 accuracy 0.6601705237515225\n",
      "\n",
      "epoch: 75  acc: 0.6602  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 77/100\n",
      "----------\n",
      "Train loss 0.5511126055300815 accuracy 0.9789890377588306\n",
      "Val loss 1.5032761647151067 accuracy 0.6613885505481121\n",
      "\n",
      "epoch: 76  acc: 0.6614  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 78/100\n",
      "----------\n",
      "Train loss 0.5506904958521278 accuracy 0.9805115712545676\n",
      "Val loss 1.4953903968517597 accuracy 0.6662606577344701\n",
      "\n",
      "epoch: 77  acc: 0.6663  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 79/100\n",
      "----------\n",
      "Train loss 0.551038411635797 accuracy 0.9814250913520097\n",
      "Val loss 1.5009852693631098 accuracy 0.6650426309378806\n",
      "\n",
      "epoch: 78  acc: 0.6650  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 80/100\n",
      "----------\n",
      "Train loss 0.5513524789254642 accuracy 0.9789890377588306\n",
      "Val loss 1.497590225476485 accuracy 0.6711327649208282\n",
      "\n",
      "epoch: 79  acc: 0.6711  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 81/100\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5503887580436411 accuracy 0.9799025578562728\n",
      "Val loss 1.5003786453833947 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 80  acc: 0.6675  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 82/100\n",
      "----------\n",
      "Train loss 0.5503568562489112 accuracy 0.9805115712545676\n",
      "Val loss 1.5079305034417372 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 81  acc: 0.6675  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 83/100\n",
      "----------\n",
      "Train loss 0.550168703481989 accuracy 0.9817295980511571\n",
      "Val loss 1.5138665162600005 accuracy 0.6601705237515225\n",
      "\n",
      "epoch: 82  acc: 0.6602  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 84/100\n",
      "----------\n",
      "Train loss 0.5503605893514689 accuracy 0.9789890377588306\n",
      "Val loss 1.5122165083885193 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 83  acc: 0.6626  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 85/100\n",
      "----------\n",
      "Train loss 0.5504141091143043 accuracy 0.9820341047503045\n",
      "Val loss 1.5110759826806874 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 84  acc: 0.6626  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 86/100\n",
      "----------\n",
      "Train loss 0.5502224049521881 accuracy 0.9817295980511571\n",
      "Val loss 1.5095217640583332 accuracy 0.6674786845310596\n",
      "\n",
      "epoch: 85  acc: 0.6675  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 87/100\n",
      "----------\n",
      "Train loss 0.5500639046280129 accuracy 0.9811205846528623\n",
      "Val loss 1.5067364435929518 accuracy 0.6613885505481121\n",
      "\n",
      "epoch: 86  acc: 0.6614  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 88/100\n",
      "----------\n",
      "Train loss 0.5512563111712632 accuracy 0.979293544457978\n",
      "Val loss 1.5057911047568688 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 87  acc: 0.6626  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 89/100\n",
      "----------\n",
      "Train loss 0.5504517717268861 accuracy 0.9805115712545676\n",
      "Val loss 1.5068986186614404 accuracy 0.6613885505481121\n",
      "\n",
      "epoch: 88  acc: 0.6614  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 90/100\n",
      "----------\n",
      "Train loss 0.5500745356661602 accuracy 0.980816077953715\n",
      "Val loss 1.507433226475349 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 89  acc: 0.6626  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 91/100\n",
      "----------\n",
      "Train loss 0.5501849396714886 accuracy 0.9805115712545676\n",
      "Val loss 1.5044842683351958 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 90  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 92/100\n",
      "----------\n",
      "Train loss 0.5501610601989968 accuracy 0.9811205846528623\n",
      "Val loss 1.5059040784835815 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 91  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 93/100\n",
      "----------\n",
      "Train loss 0.5506807287919868 accuracy 0.9811205846528623\n",
      "Val loss 1.5028312848164485 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 92  acc: 0.6626  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 94/100\n",
      "----------\n",
      "Train loss 0.5503998265683072 accuracy 0.9802070645554202\n",
      "Val loss 1.5042037459520192 accuracy 0.6626065773447015\n",
      "\n",
      "epoch: 93  acc: 0.6626  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 95/100\n",
      "----------\n",
      "Train loss 0.549923512542132 accuracy 0.9835566382460413\n",
      "Val loss 1.504800374691303 accuracy 0.6613885505481121\n",
      "\n",
      "epoch: 94  acc: 0.6614  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 96/100\n",
      "----------\n",
      "Train loss 0.5503118680518808 accuracy 0.9814250913520097\n",
      "Val loss 1.50454947581658 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 95  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 97/100\n",
      "----------\n",
      "Train loss 0.5500467824704439 accuracy 0.9814250913520097\n",
      "Val loss 1.5048936834702125 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 96  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 98/100\n",
      "----------\n",
      "Train loss 0.5504100710442923 accuracy 0.980816077953715\n",
      "Val loss 1.5036435952553382 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 97  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 99/100\n",
      "----------\n",
      "Train loss 0.5498182721508359 accuracy 0.9814250913520097\n",
      "Val loss 1.5044375107838557 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 98  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n",
      "Epoch 100/100\n",
      "----------\n",
      "Train loss 0.5504140211540518 accuracy 0.9799025578562728\n",
      "Val loss 1.5046560351665204 accuracy 0.6638246041412911\n",
      "\n",
      "epoch: 99  acc: 0.6638  best epoch: 35  best acc: 0.6870 lr: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_everything()\n",
    "EPOCHS = 100\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "            \n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(model,train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train))\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(model,test_data_loader,loss_fn, device, len(df_test))\n",
    "\n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_wikiart_title_cls_transf_LS_0.13.pth')\n",
    "        best_accuracy = val_acc\n",
    "        best_epoch = epoch\n",
    "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f} lr: {:.4f}'.format(\n",
    "            epoch, val_acc, best_epoch, best_accuracy,optimizer.param_groups[0]['lr']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971c4d4",
   "metadata": {},
   "source": [
    "Confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29edfea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8871, 0.8848, 0.8912, 0.8898, 0.7549, 0.8843], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_conf_freq (model, dataloader):\n",
    "    model.eval()\n",
    "    conf_score = torch.zeros([6]).to(device)\n",
    "    count = torch.zeros([6]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for d in dataloader:\n",
    "            input_ids = d[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask = d[\"mask\"].squeeze(1).to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                ).logits\n",
    "            softmaxes = F.softmax(outputs, dim=1)\n",
    "\n",
    "            for i in range (len(targets)):\n",
    "                 \n",
    "                confidence = softmaxes[i][targets[i].long()]\n",
    "                conf_score[targets[i].long()] += confidence\n",
    "                count[targets[i].long()] += 1\n",
    "            conf_avg = conf_score/count\n",
    "    return conf_avg\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_wikiart_title_cls_transf_LS_0.13.pth'))\n",
    "conf_score_train = get_conf_freq(model, train_data_loader)\n",
    "conf_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd811d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12b1c31",
   "metadata": {},
   "source": [
    "ECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62001e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17542988061904907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "TRAIN_BATCH_SIZE=32\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_wikiart_title_cls_transf_LS_0.13.pth'))\n",
    "\n",
    "labels = []\n",
    "for i in range(len(test_data_loader.dataset)):\n",
    "    label = test_data_loader.dataset[i]['targets']\n",
    "    labels.append(label)\n",
    "labels = np.array(labels)\n",
    "\n",
    "class _ECELoss(nn.Module):\n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(_ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece\n",
    "    \n",
    "def evaluation(model, testing_loader):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    pred_all = []\n",
    "    target_all = []\n",
    "    logits_list, labels_list = [], [] \n",
    "    with torch.no_grad():\n",
    "        for d in testing_loader:\n",
    "            input_ids = d[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask = d[\"mask\"].squeeze(1).to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            outputs = model(input_ids=input_ids,attention_mask=attention_mask).logits\n",
    "            loss_val = loss_fn(outputs.squeeze(), targets.long())\n",
    "            predictions = torch.max(outputs, 1)[1].view(targets.size()).data\n",
    "            pred_all.append(outputs)\n",
    "            target_all.append(targets)\n",
    "            \n",
    "            f1 = f1_score(targets.data.cpu(), predictions.cpu(), average='macro')\n",
    "            num_corrects = (predictions == targets.data).float().sum()\n",
    "            acc = 100.0 * num_corrects / TRAIN_BATCH_SIZE\n",
    "            total_acc += acc.item()\n",
    "            total_loss += loss_val.item()\n",
    "            count += 1\n",
    "        logits_all = torch.cat(pred_all).cuda()\n",
    "        labels_all = torch.cat(target_all).cuda()\n",
    "    return total_acc/count,f1, logits_all, labels_all\n",
    "ece_criterion = _ECELoss().to(device)\n",
    "accuracy,total_f1, logits_all,labels_all = evaluation(model, test_data_loader)\n",
    "\n",
    "logits_all = logits_all.view(-1,6)\n",
    "labels_all = labels_all.view(-1)\n",
    "temperature_ece = ece_criterion(logits_all, labels_all).item()\n",
    "temperature_ece"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8b5931d",
   "metadata": {},
   "source": [
    "Reliability Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14075110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def ece_eval(preds, targets, n_bins=15, bg_cls = -1):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    confidences, predictions = np.max(preds,1), np.argmax(preds,1)\n",
    "    confidences, predictions = confidences[targets>bg_cls], predictions[targets>bg_cls]\n",
    "    accuracies = (predictions == targets[targets>bg_cls]) \n",
    "    Bm, acc, conf = np.zeros(n_bins), np.zeros(n_bins), np.zeros(n_bins)\n",
    "    ece = 0.0\n",
    "    bin_idx = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = np.logical_and(confidences > bin_lower, confidences <= bin_upper)\n",
    "        #in_bin = in_bin[targets>backgound_class]\n",
    "        bin_size = np.sum(in_bin)\n",
    "        \n",
    "        Bm[bin_idx] = bin_size\n",
    "        if bin_size > 0:  \n",
    "            accuracy_in_bin = np.sum(accuracies[in_bin])\n",
    "            acc[bin_idx] = accuracy_in_bin / Bm[bin_idx]\n",
    "            confidence_in_bin = np.sum(confidences[in_bin])\n",
    "            conf[bin_idx] = confidence_in_bin / Bm[bin_idx]\n",
    "        bin_idx += 1\n",
    "        \n",
    "    ece_all = Bm * np.abs((acc - conf))/ Bm.sum()\n",
    "    ece = ece_all.sum() \n",
    "    return ece, acc, conf, Bm\n",
    "\n",
    "\n",
    "def get_reliability_diagram(conf_avg, acc_avg, legend=None, leg_idx=0, n_bins=10, fig=2):\n",
    "    plt.figure(fig)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--',label = 'Perfect Calibration')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(0, 1.1, 1/n_bins))\n",
    "    plt.title('{}'.format(fig))\n",
    "    plt.plot(conf_avg[acc_avg>0],acc_avg[acc_avg>0], marker='.', label = legend)\n",
    "    plt.legend()\n",
    "    plt.savefig('ece_reliability_diag_{}.png'.format(fig),dpi=300)\n",
    "    \n",
    "logits_all =F.softmax(logits_all, dim=1).detach().cpu().numpy()\n",
    "labels_all =labels_all.detach().cpu().numpy()\n",
    "ece, acc, conf, Bm = ece_eval(logits_all, labels_all)\n",
    "get_reliability_diagram(conf, acc, legend='Reliability Diagram', fig='reliability_diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfce18ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.37366244\n",
      " 0.44952483 0.49368395 0.56920671 0.63214328 0.69600672 0.76678581\n",
      " 0.82179543 0.90092757 0.        ] <class 'numpy.ndarray'>\n",
      "[0.         0.         0.         0.         0.         0.28571429\n",
      " 0.6        0.72727273 0.5        0.54545455 0.63636364 0.42857143\n",
      " 0.61728395 0.72712418 0.        ] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(conf, type(conf))\n",
    "print(acc,type(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bc8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
